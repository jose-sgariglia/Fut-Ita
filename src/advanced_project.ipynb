{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie da scaricare\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.constant import *\n",
    "from datetime import datetime\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Settaggio\n",
    "def setup_logging(log_file):\n",
    "    \"\"\"Imposta il logging per il modello\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Rimuove eventuali handler esistenti per evitare duplicazione\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    # Aggiungi un FileHandler e uno StreamHandler\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    stream_handler = logging.StreamHandler()\n",
    "\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def close_logger(logger):\n",
    "    \"\"\"Chiude tutti gli handler associati al logger\"\"\"\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economici\n",
    "Aggiungere i dati del Real GDP al dataset italiano per valutarne la crescita nazionale e il PIL pro Capite per una visione dell'economia della popolazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica datasets\n",
    "\n",
    "dataset_real_gdp = pd.read_csv(RAW_DATA_ECONOMICS + 'real_gdp.csv')\n",
    "dataset_ppc = pd.read_csv(RAW_DATA_ECONOMICS + 'pil_pro_capite.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real GDP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset\n",
    "\n",
    "columns = {\n",
    "    'DATE': 'Anno',\n",
    "    'RGDPNAITA666NRUG': \"real_GDP\"\n",
    "}\n",
    "\n",
    "def convert_date_to_year(date):\n",
    "    return int(date[:4])\n",
    "\n",
    "def convert_to_discrate_value(value):\n",
    "    return int(value)\n",
    "\n",
    "dataset_real_gdp = dataset_real_gdp.rename(columns=columns)\n",
    "dataset_real_gdp['Anno'] = dataset_real_gdp['Anno'].apply(convert_date_to_year)\n",
    "dataset_real_gdp['real_GDP'] = dataset_real_gdp['real_GDP'].apply(convert_to_discrate_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] Real GDP Italian\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(dataset_real_gdp['Anno'], dataset_real_gdp['real_GDP'], label='Real GDP')\n",
    "\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.ylabel('Real GDP')\n",
    "plt.title('Real GDP Italian')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(ECONOMICS_ORIGINAL_CHART_PATH, exist_ok=True)\n",
    "\n",
    "plt.savefig(ECONOMICS_ORIGINAL_CHART_PATH + 'real_gdp.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Imputation\n",
    "Prevediamo i dati del 2020, 2021, 2022 e 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_series = dataset_real_gdp['real_GDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search per trovare il miglior modello ARIMA\n",
    "\n",
    "p = range(0, 5)\n",
    "d = range(0, 2)  \n",
    "q = range(0, 5)\n",
    "\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "best_aic = float(\"inf\")\n",
    "best_pdq = None\n",
    "best_model = None\n",
    "\n",
    "for param in pdq:\n",
    "    try:\n",
    "        model = ARIMA(gdp_series, order=param)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_pdq = param\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Modello per la predizione dei dati futuri\n",
    "\n",
    "model = ARIMA(gdp_series, order=best_pdq)\n",
    "model_fit = model.fit()\n",
    "\n",
    "forecast = model_fit.forecast(steps=4)\n",
    "forecast_index = [2020, 2021, 2022, 2023]\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Anno\": forecast_index,\n",
    "    \"Forecast\": forecast.astype(int)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(dataset_real_gdp['Anno'], dataset_real_gdp['real_GDP'], label='Real GDP')\n",
    "plt.plot(forecast_df['Anno'], forecast_df['Forecast'], label='Forecast')\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Real GDP')\n",
    "plt.title('Real GDP Italian')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(ECONOMICS_PREDICTION_CHART_PATH, exist_ok=True)\n",
    "\n",
    "plt.savefig(ECONOMICS_PREDICTION_CHART_PATH + 'real_gdp_with_prediction.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva il dataset completo\n",
    "\n",
    "forecast_df.rename(columns={'Forecast': 'real_GDP'}, inplace=True)\n",
    "\n",
    "dataset_real_gdp = pd.concat([dataset_real_gdp, forecast_df], ignore_index=True)\n",
    "\n",
    "os.makedirs(CLEANED_DATA_ECONOMICS, exist_ok=True)\n",
    "\n",
    "dataset_real_gdp.to_csv(CLEANED_DATA_ECONOMICS + 'real_gdp.csv', index=False)\n",
    "dataset_real_gdp.to_parquet(CLEANED_DATA_ECONOMICS + 'real_gdp.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIL Pro Capite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "columns = {\n",
    "    'DATE': 'Anno',\n",
    "    'NYGDPPCAPKDITA': \"pil_pro_capite\"\n",
    "}\n",
    "\n",
    "def convert_date_to_year(date):\n",
    "    return int(date[:4])\n",
    "\n",
    "def convert_to_discrate_value(value):\n",
    "    return int(value)\n",
    "\n",
    "dataset_ppc = dataset_ppc.rename(columns=columns)\n",
    "dataset_ppc['Anno'] = dataset_ppc['Anno'].apply(convert_date_to_year)\n",
    "dataset_ppc['pil_pro_capite'] = dataset_ppc['pil_pro_capite'].apply(convert_to_discrate_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] PIL pro capite Italian\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(dataset_ppc['Anno'], dataset_ppc['pil_pro_capite'], label='PIL pro capite')\n",
    "\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.ylabel('PIL pro capite')\n",
    "plt.title('PIL pro capite Italian')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(ECONOMICS_ORIGINAL_CHART_PATH, exist_ok=True)\n",
    "\n",
    "plt.savefig(ECONOMICS_ORIGINAL_CHART_PATH + 'pil_pro_capite.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Imputetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento librerie per ARIMA\n",
    "\n",
    "\n",
    "ppc_series = dataset_ppc['pil_pro_capite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search per trovare il miglior modello ARIMA\n",
    "\n",
    "ppc_series_reversed = ppc_series[::-1]\n",
    "\n",
    "p = range(0, 5)\n",
    "d = range(0, 2)  \n",
    "q = range(0, 5)\n",
    "\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "best_aic = float(\"inf\")\n",
    "best_pdq = None\n",
    "best_model = None\n",
    "\n",
    "for param in pdq:\n",
    "    try:\n",
    "        model = ARIMA(ppc_series_reversed, order=param)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_pdq = param\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Modello per la predizione dei dati passati\n",
    "\n",
    "model = ARIMA(ppc_series_reversed, order=best_pdq)\n",
    "model_fit = model.fit()\n",
    "\n",
    "forecast = model_fit.forecast(steps=10)\n",
    "forecast_index = [1959, 1958, 1957, 1956, 1955, 1954, 1953, 1952, 1951, 1950]\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Anno\": forecast_index,\n",
    "    \"Forecast\": forecast.astype(int)\n",
    "})  \n",
    "\n",
    "forecast_df = forecast_df.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(dataset_ppc['Anno'], dataset_ppc['pil_pro_capite'], label='PIL pro capite')\n",
    "plt.plot(forecast_df['Anno'], forecast_df['Forecast'], label='Forecast')\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('PIL pro capite')\n",
    "plt.title('PIL pro capite Italian')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(ECONOMICS_PREDICTION_CHART_PATH + 'pil_pro_capite.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva il dataset completo\n",
    "\n",
    "forecast_df = forecast_df.rename(columns={'Forecast': 'pil_pro_capite'})\n",
    "ppc_dataset = pd.concat([forecast_df, dataset_ppc], ignore_index=True)\n",
    "\n",
    "os.makedirs(CLEANED_DATA_ECONOMICS, exist_ok=True)\n",
    "\n",
    "ppc_dataset.to_csv(CLEANED_DATA_ECONOMICS + 'pil_pro_capite.csv', index=False)\n",
    "ppc_dataset.to_parquet(CLEANED_DATA_ECONOMICS + 'pil_pro_capite.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unione tra i dataset Demografici e i dataset Economici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dataset\n",
    "\n",
    "SOURCE_DEMO_PATH = CLEANED_DATA_DEMOGRAPHICS + 'by_area/ITA/'\n",
    "\n",
    "df_demo = pd.read_parquet(SOURCE_DEMO_PATH + 'popolazione.parquet')\n",
    "df_rgdp = pd.read_parquet(CLEANED_DATA_ECONOMICS + 'real_gdp.parquet')\n",
    "df_ppc = pd.read_parquet(CLEANED_DATA_ECONOMICS + 'pil_pro_capite.parquet')\n",
    "\n",
    "df_demo_rgdp = pd.merge(df_demo[df_demo['Sesso'] == 'T'], df_rgdp, on='Anno', how='inner')\n",
    "df_demo_ppc = pd.merge(df_demo[df_demo['Sesso'] == 'T'], df_ppc, on='Anno', how='inner')\n",
    "\n",
    "df_demo_rgdp_ppc = pd.merge(df_demo_rgdp, df_ppc, on='Anno', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvataggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizzazione dei dati\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_demo_rgdp[['Popolazione_Totale', 'real_GDP']] = scaler.fit_transform(df_demo_rgdp[['Popolazione_Totale', 'real_GDP']])\n",
    "df_demo_ppc[['Popolazione_Totale', 'pil_pro_capite']] = scaler.fit_transform(df_demo_ppc[['Popolazione_Totale', 'pil_pro_capite']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva i dataset completi\n",
    "\n",
    "DEMO_RGDP_PATH = CLEANED_DATA_COMBINED + \"demo_rgdp/\"\n",
    "DEMO_PPC_PATH = CLEANED_DATA_COMBINED + \"demo_ppc/\"\n",
    "\n",
    "os.makedirs(DEMO_RGDP_PATH, exist_ok=True)\n",
    "os.makedirs(DEMO_PPC_PATH, exist_ok=True)\n",
    "\n",
    "df_demo_rgdp.to_csv(DEMO_RGDP_PATH + 'demo_rgdp.csv', index=False)\n",
    "df_demo_rgdp.to_parquet(DEMO_RGDP_PATH + 'demo_rgdp.parquet', index=False)\n",
    "\n",
    "df_demo_ppc.to_csv(DEMO_PPC_PATH + 'demo_ppc.csv', index=False)\n",
    "df_demo_ppc.to_parquet(DEMO_PPC_PATH + 'demo_ppc.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] Demografia ed PIL reale Italiano (Normalizzato)\n",
    "\n",
    "DESTIONATION_PATH = COMBINED_CHART_PATH + \"DEMO_RGDP/\"\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(df_demo_rgdp['Anno'], df_demo_rgdp['Popolazione_Totale'], label='Popolazione')\n",
    "plt.plot(df_demo_rgdp['Anno'], df_demo_rgdp['real_GDP'], label='Real GDP')\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Popolazione / Real GDP')\n",
    "plt.title('Demografia ed PIL reale Italiano (Normalizzato)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(DESTIONATION_PATH, exist_ok=True)\n",
    "plt.savefig(DESTIONATION_PATH + 'demo_rgdp.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] Demografia ed PIL pro capite Italiano\n",
    "\n",
    "DESTIONATION_PATH = COMBINED_CHART_PATH + \"/DEMO_PPC/\"\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(df_demo_ppc['Anno'], df_demo_ppc['Popolazione_Totale'], label='Popolazione')\n",
    "plt.plot(df_demo_ppc['Anno'], df_demo_ppc['pil_pro_capite'], label='PIL pro capite')\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Popolazione / PIL pro capite')\n",
    "plt.title('Demografia ed PIL pro capite Italiano (Normalizzato)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(DESTIONATION_PATH, exist_ok=True)\n",
    "plt.savefig(DESTIONATION_PATH + 'demo_ppc.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demografia + Real GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Random Forest Regressor\n",
    " \n",
    "model_dir = ECO_MODEL_PATH + 'rgdp/'\n",
    "logs_dir = os.path.join(model_dir, 'logs/')\n",
    "\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Imposta il logging\n",
    "log_file = os.path.join(logs_dir,  f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "logger = setup_logging(log_file)\n",
    "\n",
    "# Aggiungi timestamp e informazioni sul dataset\n",
    "logger.info(f\"========== Report per real PIL - Demografico Economico ==========\")\n",
    "logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "\n",
    "DEMO_RGDP_PATH = CLEANED_DATA_COMBINED + \"demo_rgdp/\"\n",
    "df_demo_rgdp = pd.read_parquet(DEMO_RGDP_PATH + 'demo_rgdp.parquet')\n",
    "\n",
    "logger.info(f\"Dataset Path: {DEMO_RGDP_PATH + 'demo_rgdp.parquet'}\")\n",
    "logger.info(f\"Model: RandomForest Regressor\\n\")\n",
    "\n",
    "cutoff = 0.8\n",
    "\n",
    "cutoff_lenght = int(len(df_demo[\"Anno\"].unique()) * cutoff)\n",
    "\n",
    "logger.info(f\"Train Cut Off: {cutoff:.2f}\")\n",
    "logger.info(f\"Test Cut Off: {1 - cutoff:.2f}\\n\")\n",
    "\n",
    "try:\n",
    "    df = df_demo_rgdp.copy()\n",
    "\n",
    "    df_train = df[:cutoff_lenght]\n",
    "    df_test = df[cutoff_lenght:]\n",
    "\n",
    "    x_train = df_train[['Anno', 'real_GDP']]\n",
    "    y_train = df_train['Popolazione_Totale']\n",
    "\n",
    "    x_test = df_test[['Anno', 'real_GDP']]\n",
    "    y_test = df_test['Popolazione_Totale']\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=1000, max_depth=5, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calcola le metriche di performance\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log delle metriche\n",
    "    logger.info(f\"Metrics:\")\n",
    "    logger.info(f\"\\tMAE: {mae:.4f}\")\n",
    "    logger.info(f\"\\tMSE: {mse:.4f}\")\n",
    "    logger.info(f\"\\tRMSE: {rmse:.4f}\")\n",
    "    logger.info(f\"\\tR2 Score: {r2:.4f}\\n\")\n",
    "\n",
    "    filename = model_dir + f\"model.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Errore durante l'addestramento del modello per il dataset : {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    logger.info(f\"=====================================\\n\")\n",
    "    close_logger(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jojo/python_project/Fut-Ita/venv/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# [P]\n",
    "\n",
    "DEMO_RGDP_PATH = CLEANED_DATA_COMBINED + \"demo_rgdp/\"\n",
    "df = pd.read_parquet(DEMO_RGDP_PATH + 'demo_rgdp.parquet')\n",
    "\n",
    "model_dir = ECO_MODEL_PATH + 'rgdp/'\n",
    "model = joblib.load(model_dir + 'model.pkl')\n",
    "\n",
    "output_dir = ECONOMICS_MODEL_CHART_PATH\n",
    "\n",
    "x = df[[\"Anno\", \"real_GDP\"]].values\n",
    "y = df[\"Popolazione_Totale\"].values\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df[\"Anno\"], y, label='Reale', color='blue')\n",
    "plt.plot(df[\"Anno\"], y_pred, label='Predetto', color='red')\n",
    "\n",
    "plt.xlabel('Anno')\n",
    "plt.ylabel('Popolazione')\n",
    "plt.title('Confronto Realtà vs Predizione - Random Forest Regressor')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(output_dir, 'rgdp_confrontation.jpeg'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demografia + PIL pro capite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Random Forest Regressor\n",
    " \n",
    "model_dir = ECO_MODEL_PATH + 'ppc/'\n",
    "logs_dir = os.path.join(model_dir, 'logs/')\n",
    "\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Imposta il logging\n",
    "log_file = os.path.join(logs_dir,  f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "logger = setup_logging(log_file)\n",
    "\n",
    "# Aggiungi timestamp e informazioni sul dataset\n",
    "logger.info(f\"========== Report per PIL pro capite - Demografico Economico ==========\")\n",
    "logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "\n",
    "DEMO_PPC_PATH = CLEANED_DATA_COMBINED + \"demo_ppc/\"\n",
    "df_demo_ppc = pd.read_parquet(DEMO_PPC_PATH + 'demo_ppc.parquet')\n",
    "\n",
    "logger.info(f\"Dataset Path: {DEMO_PPC_PATH + 'demo_ppc.parquet'}\")\n",
    "logger.info(f\"Model: RandomForest Regressor\\n\")\n",
    "\n",
    "cutoff = 0.8\n",
    "\n",
    "cutoff_lenght = int(len(df_demo[\"Anno\"].unique()) * cutoff)\n",
    "\n",
    "logger.info(f\"Train Cut Off: {cutoff:.2f}\")\n",
    "logger.info(f\"Test Cut Off: {1 - cutoff:.2f}\\n\")\n",
    "\n",
    "try:\n",
    "    df = df_demo_ppc.copy()\n",
    "\n",
    "    df_train = df[:cutoff_lenght]\n",
    "    df_test = df[cutoff_lenght:]\n",
    "\n",
    "    x_train = df_train[['Anno', 'pil_pro_capite']]\n",
    "    y_train = df_train['Popolazione_Totale']\n",
    "\n",
    "    x_test = df_test[['Anno', 'pil_pro_capite']]\n",
    "    y_test = df_test['Popolazione_Totale']\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=1000, max_depth=5, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    logger.info(f\"Metrics:\")\n",
    "    logging.info(f\"\\tMAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    logging.info(f\"\\tMSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "    logging.info(f\"\\tRMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n",
    "    logging.info(f\"\\tR2: {r2_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "    filename = model_dir + f\"model.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Errore durante l'addestramento del modello per il dataset : {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    logger.info(f\"=====================================\\n\")\n",
    "    close_logger(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambientali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dataset\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for file in os.listdir(RAW_DATA_CLIMATE_CHANGE):\n",
    "    if file.endswith('.csv'):\n",
    "        dataset.append(pd.read_csv(RAW_DATA_CLIMATE_CHANGE + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dataset\n",
    "columns = {\n",
    "    'name': 'Area'\n",
    "}\n",
    "\n",
    "for i, df in enumerate(dataset):\n",
    "    df = df[df['code'].str.contains('ITA')].copy()\n",
    "    del df['code']\n",
    "\n",
    "    df['name'] = df['name'].replace(MAPPING_REGION)\n",
    "    df = df.rename(columns=columns)\n",
    "\n",
    "    df.columns = [col[:4] if col != 'Area' else col for col in df.columns]\n",
    "    df = df[[col for col in df.columns if col == 'Area' or (col.isdigit() and int(col) <= 2023)]]\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'Area':\n",
    "            df[col] = df[col].apply(lambda x: float(x.replace(',', '.')) if isinstance(x, str) else x)\n",
    "    dataset[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Struttura del dataset\n",
    "\n",
    "df = pd.merge(dataset[0], dataset[1], on='Area', how='inner')\n",
    "\n",
    "os.makedirs(CLEANED_DATA_CLIMATE_CHANGE, exist_ok=True)\n",
    "\n",
    "df.to_csv(CLEANED_DATA_CLIMATE_CHANGE + 'tas.csv', index=False)\n",
    "df.to_parquet(CLEANED_DATA_CLIMATE_CHANGE + 'tas.parquet', index=False)\n",
    "\n",
    "# by Area\n",
    "for key in df['Area'].unique():\n",
    "    code = ITALIAN_REGION_CODE[key]\n",
    "    df_area = df[df['Area'] == key].copy()\n",
    "    del df_area['Area']\n",
    "\n",
    "    path = CLEANED_DATA_CLIMATE_CHANGE + f'by_area/{code}/'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    df_melt = pd.melt(df_area, var_name='Anno', value_name='tas')\n",
    "    df_melt['Anno'] = df_melt['Anno'].astype(int)\n",
    "    df_melt.to_csv(path + 'tas.csv', index=False)\n",
    "    df_melt.to_parquet(path + 'tas.parquet', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unione Dati Demografici e Dati Economici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAS_PATH = CLEANED_DATA_CLIMATE_CHANGE + 'by_area/ITA/tas.parquet'\n",
    "DEMO_PATH = CLEANED_DATA_DEMOGRAPHICS + 'by_area/ITA/popolazione.parquet'\n",
    "\n",
    "df_tas = pd.read_parquet(TAS_PATH)\n",
    "df_demo = pd.read_parquet(DEMO_PATH)\n",
    "\n",
    "df = pd.merge(df_tas, df_demo[df_demo['Sesso'] == 'T'], on='Anno', how='inner')\n",
    "\n",
    "# Salva il dataset completo\n",
    "DEMO_TAS_PATH = CLEANED_DATA_COMBINED + 'demo_tas/'\n",
    "os.makedirs(DEMO_TAS_PATH, exist_ok=True)\n",
    "\n",
    "df.to_csv(DEMO_TAS_PATH + 'demo_tas.csv', index=False)\n",
    "df.to_parquet(DEMO_TAS_PATH + 'demo_tas.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizzazione dei dati\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[['Popolazione_Totale', 'tas']] = scaler.fit_transform(df[['Popolazione_Totale', 'tas']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] Demografia e Temperatura Italiana\n",
    "\n",
    "DESTIONATION_PATH = COMBINED_CHART_PATH + \"DEMO_TAS/\"\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(df['Anno'], df['Popolazione_Totale'], label='Popolazione')\n",
    "plt.plot(df['Anno'], df['tas'], label='Temperatura')\n",
    "plt.xlabel('Anno')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Popolazione / Temperatura')\n",
    "plt.title('Demografia e Temperatura Italiana (Normalizzato)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "os.makedirs(DESTIONATION_PATH, exist_ok=True)\n",
    "plt.savefig(DESTIONATION_PATH + 'demo_tas.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Random Forest Regressor\n",
    " \n",
    "model_dir = CCH_MODEL_PATH + \"tas/\"\n",
    "logs_dir = os.path.join(model_dir, 'logs/')\n",
    "\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Imposta il logging\n",
    "log_file = os.path.join(logs_dir,  f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "logger = setup_logging(log_file)\n",
    "\n",
    "# Aggiungi timestamp e informazioni sul dataset\n",
    "logger.info(f\"========== Report per TAS - Demografico Ambientale ==========\")\n",
    "logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "\n",
    "DEMO_TAS_PATH = CLEANED_DATA_COMBINED + \"demo_tas/\"\n",
    "df = pd.read_parquet(DEMO_TAS_PATH + 'demo_tas.parquet')\n",
    "\n",
    "logger.info(f\"Dataset Path: {DEMO_TAS_PATH + 'demo_tas.parquet'}\")\n",
    "logger.info(f\"Model: RandomForest Regressor\\n\")\n",
    "\n",
    "cutoff = 0.8\n",
    "\n",
    "cutoff_lenght = int(len(df_demo[\"Anno\"].unique()) * cutoff)\n",
    "\n",
    "logger.info(f\"Train Cut Off: {cutoff:.2f}\")\n",
    "logger.info(f\"Test Cut Off: {1 - cutoff:.2f}\\n\")\n",
    "\n",
    "try:\n",
    "    df_train = df[:cutoff_lenght]\n",
    "    df_test = df[cutoff_lenght:]\n",
    "\n",
    "    x_train = df_train[['Anno', 'tas']]\n",
    "    y_train = df_train['Popolazione_Totale']\n",
    "\n",
    "    x_test = df_test[['Anno', 'tas']]\n",
    "    y_test = df_test['Popolazione_Totale']\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=1000, max_depth=5, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    logging.info(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    logging.info(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "    logging.info(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n",
    "    logging.info(f\"R2: {r2_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "    filename = model_dir + f\"model.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Errore durante l'addestramento del modello per il dataset : {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    logger.info(f\"=====================================\\n\")\n",
    "    close_logger(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economico + Ambientale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dataset\n",
    "\n",
    "code = 'ITA'\n",
    "\n",
    "df_demo = pd.read_parquet(CLEANED_DATA_DEMOGRAPHICS + 'by_area/' + code + '/popolazione.parquet') \n",
    "df_eco = pd.read_parquet(CLEANED_DATA_ECONOMICS + 'real_gdp.parquet')\n",
    "df_env = pd.read_parquet(CLEANED_DATA_CLIMATE_CHANGE + 'by_area/' + code + '/tas.parquet')\n",
    "\n",
    "df_demo_eco = pd.merge(df_demo[df_demo['Sesso'] == 'T'], df_eco, on='Anno', how='inner')\n",
    "df_all = pd.merge(df_demo_eco, df_env, on='Anno', how='inner')\n",
    "\n",
    "# Salva il dataset completo\n",
    "path = CLEANED_DATA_COMBINED + 'all/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "df_all.to_csv(path + 'all.csv', index=False)\n",
    "df_all.to_parquet(path + 'all.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Random Forest Regressor\n",
    "\n",
    "model_dir = ALL_MODEL_PATH\n",
    "logs_dir = os.path.join(model_dir, 'logs/')\n",
    "\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Imposta il logging\n",
    "log_file = os.path.join(logs_dir,  f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "logger = setup_logging(log_file)\n",
    "\n",
    "# Aggiungi timestamp e informazioni sul dataset\n",
    "logger.info(f\"========== Report per modello completo - Demografico Economico Ambientale ==========\")\n",
    "logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "\n",
    "ALL_PATH = CLEANED_DATA_COMBINED + \"all/\"\n",
    "df = pd.read_parquet(ALL_PATH + 'all.parquet')\n",
    "\n",
    "logger.info(f\"Dataset Path: {ALL_PATH + 'all.parquet'}\")\n",
    "logger.info(f\"Model: RandomForest Regressor\\n\")\n",
    "\n",
    "cutoff = 0.8\n",
    "\n",
    "cutoff_lenght = int(len(df_demo[\"Anno\"].unique()) * cutoff)\n",
    "\n",
    "logger.info(f\"Train Cut Off: {cutoff:.2f}\")\n",
    "logger.info(f\"Test Cut Off: {1 - cutoff:.2f}\\n\")\n",
    "\n",
    "try:\n",
    "    df_train = df[:cutoff_lenght]\n",
    "    df_test = df[cutoff_lenght:]\n",
    "\n",
    "    x_train = df_train[['Anno', 'real_GDP', 'tas']]\n",
    "    y_train = df_train['Popolazione_Totale']\n",
    "\n",
    "    x_test = df_test[['Anno', 'real_GDP', 'tas']]\n",
    "    y_test = df_test['Popolazione_Totale']\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=1000, max_depth=5, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    logger.info(f\"Metrics:\")\n",
    "    logging.info(f\"\\tMAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    logging.info(f\"\\tMSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "    logging.info(f\"\\tRMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n",
    "    logging.info(f\"\\tR2: {r2_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "    filename = model_dir + f\"model.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Errore durante l'addestramento del modello per il dataset : {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    logger.info(f\"=====================================\\n\")\n",
    "    close_logger(logger)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
