{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formattazione dei dataset ISTAT\n",
    "Ri-formatto i dataset ISTAT con procedura di cleaning. Una volta creati i vari dataset, verranno mergiati in un unico dataset a cui si procederà al feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie e costanti da usare\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.constant import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1982 agli anni 1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_RAW_DATA + '1982-1991/'\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        datasets.append(pd.read_csv(SOURCE_PATH + filename, sep=';', encoding='latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dataset = dataset[dataset[\"Tipo aggregazione\"].isin([\"Regione\", \"Totale\"])]\n",
    "    dataset = dataset[dataset[\"Sesso\"] != \"T\"]\n",
    "    dataset = dataset[dataset[\"ETA\"] != 99]\n",
    "    \n",
    "    dataset = dataset.drop(columns=[\"Tipo aggregazione\", \"Codice aggregazione\"])\n",
    "    dataset[\"Aggregazione\"] = dataset[\"Aggregazione\"].str.capitalize()\n",
    "    datasets[i] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Aggregazione\": \"AREA\",\n",
    "    \"Sesso\": \"SESSO\",\n",
    "    \"ETA\": \"ETA\",\n",
    "    \"Anno\": \"ANNO\"\n",
    "}\n",
    "    \n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dataset = dataset.melt(id_vars=[ \"Aggregazione\", \"Sesso\", \"ETA\"],\n",
    "                        var_name=\"Anno\", value_name=\"Popolazione\")\n",
    "    \n",
    "    dataset['Anno'] = dataset['Anno'].str.extract('(\\d+)').astype(int)\n",
    "    dataset['Fascia_Eta'] = pd.cut(dataset['ETA'], bins=AGE_GROUP[\"age_bins\"], labels=AGE_GROUP[\"age_labels\"], right=True, include_lowest=True)\n",
    "\n",
    "    dataset_pivot = dataset.pivot_table(index=['Aggregazione', 'Anno', 'Sesso'], \n",
    "                                        columns='Fascia_Eta', \n",
    "                                        values='Popolazione', \n",
    "                                        aggfunc='sum',\n",
    "                                        observed=True).reset_index()\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    datasets[i] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_1982-1991.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_1982-1991.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1992 agli anni 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_RAW_DATA + '1992-2001/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        year = filename.split('.')[0]\n",
    "        datasets[year] = pd.read_csv(SOURCE_PATH + filename, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df[df[\"Sesso\"] != \"Totale\"]\n",
    "    df = df.drop(columns=[\"Codice regione\"])\n",
    "    datasets[k] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"AREA\",\n",
    "    \"Sesso\": \"SESSO\",\n",
    "    \"ETA\": \"ETA\",\n",
    "    \"Anno\": \"ANNO\"\n",
    "}\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    df[\"Sesso\"] = df[\"Sesso\"].replace({\"Maschi\": \"M\", \"Femmine\": \"F\", \"Totale\": \"T\"})\n",
    "    df[\"ETA\"] = df[\"ETA\"].replace({\"100 e oltre\": 100}).astype(int)\n",
    "    df[\"Popolazione\"] = df[\"Popolazione\"].astype(int)\n",
    "    \n",
    "    \n",
    "    df['Fascia_Eta'] = pd.cut(df['ETA'], bins=AGE_GROUP[\"age_bins\"], labels=AGE_GROUP[\"age_labels\"], right=True, include_lowest=True)\n",
    "\n",
    "    dataset_pivot = df.pivot_table(index=['Regione', 'Anno', 'Sesso'], \n",
    "                                        columns='Fascia_Eta', \n",
    "                                        values='Popolazione', \n",
    "                                        aggfunc='sum',\n",
    "                                        observed=True).reset_index()\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    datasets[k] = dataset_pivot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visto che il dataset di questo periodo non presentano come AREA l'Italia, dobbiamo applicare tecniche di feature engineering per crearla artifecialmente. \\\n",
    "Semplicemente sommiamo di uno specifico anno e sesso per ogni regione e creamo i dati relativi al paese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del terrorio nazionale\n",
    "\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df: pd.DataFrame\n",
    "    years = list(df[\"ANNO\"].unique())\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = df[df[\"ANNO\"] == year]\n",
    "        \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"SESSO\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"AREA\": \"Italia\",\n",
    "            \"ANNO\": year,\n",
    "            \"SESSO\": \"M\",\n",
    "            \"0-9\": df_year_m[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_m[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_m[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_m[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_m[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_m[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_m[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_m[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_m[\"80+\"].sum(),\n",
    "        }\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"SESSO\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"AREA\": \"Italia\",\n",
    "            \"ANNO\": year,\n",
    "            \"SESSO\": \"F\",\n",
    "            \"0-9\": df_year_f[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_f[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_f[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_f[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_f[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_f[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_f[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_f[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_f[\"80+\"].sum(),\n",
    "        }\n",
    "        new_item_f = pd.DataFrame([new_item_f])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_item_f], ignore_index=True)\n",
    "        datasets[k] = update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "final_dataset = final_dataset.sort_values(by=[\"AREA\", \"ANNO\", \"SESSO\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_1992-2001.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_1992-2001.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 2002 agli anni 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il file CSV di questo dataset è formattato in modo non comune e ciò complica la lettura da parte della libreria pandas. \\\n",
    "Per risolvere questo problema, creamo un codice che dal fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatazione dei file CSV\n",
    "SOURCE_PATH = PATH_RAW_DATA + '2002-2018/'\n",
    "\n",
    "DESTINATION_PATH = SOURCE_PATH + 'formatted/'\n",
    "\n",
    "BLACKLIST = [\n",
    "    \"\\\"Ricostruzione della popolazione intercensuaria - Popolazione al 1° gennaio per età\\\"\\n\", \n",
    "    \"\\n\",\n",
    "    \"\\\"Popolazione per età, vista per territorio - Tutte le regioni\\\"\\n\"\n",
    "]\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Divide una lista in sotto-liste di lunghezza n.\"\"\"\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "    \n",
    "    lines = []\n",
    "    with open(SOURCE_PATH + filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.replace('Territorio/Età;', 'Codice regione;Regione') for line in lines]\n",
    "        lines = [line.replace(';', ',') for line in lines]\n",
    "        lines = [line.replace(',,', ',') for line in lines]\n",
    "        lines = [line for line in lines if line not in BLACKLIST]\n",
    "    chunked_list = chunk_list(lines, 70)\n",
    "    \n",
    "    for chunck in chunked_list:\n",
    "        year = int(chunck[0].split(' ')[-1][:-2])\n",
    "        if \"Tutte le cittadinanze\" not in chunck[0]:\n",
    "            continue\n",
    "        \n",
    "        chunck = chunck[1:]\n",
    "        gender_chunk = chunk_list(chunck, 23)\n",
    "        \n",
    "        for inner_chunck in gender_chunk:\n",
    "            inner_chunck = inner_chunck[:-1]\n",
    "            gender = inner_chunck[1].split(',')[-1].strip()\n",
    "            del inner_chunck[1]\n",
    "            if gender not in [\"Maschi\", \"Femmine\"]:\n",
    "                continue\n",
    "            \n",
    "            with open(DESTINATION_PATH + f\"{year}_{gender[0]}.csv\", 'w') as f:\n",
    "                f.writelines(inner_chunck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = DESTINATION_PATH\n",
    "\n",
    "temp = {\n",
    "    str(year): {}\n",
    "    for year in range(2002, 2019 + 1)\n",
    "}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if not filename.endswith('.csv'):\n",
    "        continue\n",
    "    name = filename.split('.')[0]\n",
    "    year, gender = name.split('_')\n",
    "    \n",
    "    item = {\n",
    "        gender: pd.read_csv(SOURCE_PATH + filename, encoding='latin1')\n",
    "    }\n",
    "    temp[year].update(item)\n",
    "    \n",
    "    \n",
    "datasets = {}\n",
    "for year, data in temp.items():\n",
    "    for gender, df in data.items():\n",
    "        df[\"Sesso\"] = gender \n",
    "        data[gender] = df\n",
    "    datasets[year] = pd.concat(data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    if int(k) != 2019:    \n",
    "        df = df.drop(columns=[\"Codice regione\"])\n",
    "        datasets[k] = df\n",
    "        \n",
    "del datasets[\"2019\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"AREA\",\n",
    "    \"Sesso\": \"SESSO\",\n",
    "    \"Anno\": \"ANNO\"\n",
    "}\n",
    "\n",
    "def create_age_bins(df):\n",
    "        age_bins = {\n",
    "            '0-9': df[[str(i) for i in range(0, 10)]].sum(axis=1),\n",
    "            '10-19': df[[str(i) for i in range(10, 20)]].sum(axis=1),\n",
    "            '20-29': df[[str(i) for i in range(20, 30)]].sum(axis=1),\n",
    "            '30-39': df[[str(i) for i in range(30, 40)]].sum(axis=1),\n",
    "            '40-49': df[[str(i) for i in range(40, 50)]].sum(axis=1),\n",
    "            '50-59': df[[str(i) for i in range(50, 60)]].sum(axis=1),\n",
    "            '60-69': df[[str(i) for i in range(60, 70)]].sum(axis=1),\n",
    "            '70-79': df[[str(i) for i in range(70, 80)]].sum(axis=1),\n",
    "            '80+': df[[str(i) for i in range(80, 101)]].sum(axis=1)  # Età da 80 a 100 e oltre\n",
    "        }\n",
    "\n",
    "        # Creiamo un nuovo DataFrame solo con le colonne rilevanti\n",
    "        df_age_bins = pd.DataFrame(age_bins)\n",
    "        \n",
    "        return df_age_bins\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    \n",
    "    df_age_bins = create_age_bins(df)\n",
    "    df_final = pd.concat([df[['Anno', 'Regione', 'Sesso']], df_age_bins], axis=1)\n",
    "    df_final = df_final.rename(columns=COLUMN_NAMES)\n",
    "    datasets[k] = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del territorio nazionale\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df: pd.DataFrame\n",
    "    years = list(df[\"ANNO\"].unique())\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = df[df[\"ANNO\"] == year]\n",
    "        \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"SESSO\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"AREA\": \"Italia\",\n",
    "            \"ANNO\": year,\n",
    "            \"SESSO\": \"M\",\n",
    "            \"0-9\": df_year_m[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_m[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_m[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_m[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_m[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_m[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_m[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_m[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_m[\"80+\"].sum(),\n",
    "        }\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"SESSO\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"AREA\": \"Italia\",\n",
    "            \"ANNO\": year,\n",
    "            \"SESSO\": \"F\",\n",
    "            \"0-9\": df_year_f[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_f[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_f[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_f[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_f[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_f[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_f[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_f[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_f[\"80+\"].sum(),\n",
    "        }\n",
    "        new_item_f = pd.DataFrame([new_item_f])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_item_f], ignore_index=True)\n",
    "        datasets[k] = update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "final_dataset = final_dataset.sort_values(by=[\"AREA\", \"ANNO\", \"SESSO\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_2002-2018.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_2002-2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 2019 agli anni 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_RAW_DATA + '2019-2024/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv') and filename != '2024.csv':\n",
    "        year = filename.split('.')[0]\n",
    "        datasets[year] = pd.read_csv(SOURCE_PATH + filename, skiprows=1, encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "keep_columns = [\"Regione\", \"ETA\", \"Totale maschi\", \"Totale femmine\"]\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df[df[\"ETA\"] != 999]\n",
    "    df = df.drop(columns=[col for col in df.columns if col not in keep_columns])\n",
    "    datasets[k] = df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"AREA\",\n",
    "}\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"ANNO\"] = int(k)\n",
    "    \n",
    "    # Suddivisione tra maschi e femmine \n",
    "    df_male = df[[\"ANNO\", \"Regione\", \"ETA\", \"Totale maschi\"]].copy()\n",
    "    df_male[\"SESSO\"] = \"M\"\n",
    "    df_male.rename(columns={\"Totale maschi\": \"Popolazione\"}, inplace=True)\n",
    "    \n",
    "    df_female = df[[\"ANNO\", \"Regione\", \"ETA\", \"Totale femmine\"]].copy()\n",
    "    df_female[\"SESSO\"] = \"F\"\n",
    "    df_female.rename(columns={\"Totale femmine\": \"Popolazione\"}, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df_male, df_female], ignore_index=True)\n",
    "    \n",
    "    df['Fascia_Eta'] = pd.cut(df['ETA'], bins=AGE_GROUP[\"age_bins\"], labels=AGE_GROUP[\"age_labels\"], right=True, include_lowest=True)\n",
    "\n",
    "    dataset_pivot = df.pivot_table(index=['Regione', 'ANNO', 'SESSO'], \n",
    "                                        columns='Fascia_Eta', \n",
    "                                        values='Popolazione', \n",
    "                                        aggfunc='sum',\n",
    "                                        observed=True).reset_index()\n",
    "    \n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    \n",
    "    datasets[k] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del terrorio nazionale\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    years = list(df[\"ANNO\"].unique())\n",
    "    for year in years:\n",
    "        df_year = df[df[\"ANNO\"] == year]\n",
    "    \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"SESSO\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"AREA\": \"Italia\",\n",
    "            \"ANNO\": year,\n",
    "            \"SESSO\": \"M\",\n",
    "            \"0-9\": df_year_m[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_m[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_m[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_m[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_m[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_m[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_m[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_m[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_m[\"80+\"].sum(),\n",
    "        }\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"SESSO\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"AREA\": \"Italia\",\n",
    "            \"ANNO\": year,\n",
    "            \"SESSO\": \"F\",\n",
    "            \"0-9\": df_year_f[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_f[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_f[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_f[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_f[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_f[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_f[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_f[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_f[\"80+\"].sum(),\n",
    "        }\n",
    "        new_item_f = pd.DataFrame([new_item_f])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_item_f], ignore_index=True)\n",
    "        datasets[k] = update_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset = final_dataset.sort_values(by=[\"AREA\", \"ANNO\", \"SESSO\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_2019-2023.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_2019-2023.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
