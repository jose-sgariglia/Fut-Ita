{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formattazione dei dataset ISTAT\n",
    "Ri-formatto i dataset ISTAT con procedura di cleaning. Una volta creati i vari dataset, verranno mergiati in un unico dataset a cui si procederÃ  al feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie e costanti da usare\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.constant import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1982 agli anni 1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_RAW_DATA + '1982-1991/'\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        datasets.append(pd.read_csv(SOURCE_PATH + filename, sep=';', encoding='latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dataset = dataset[dataset[\"Tipo aggregazione\"].isin([\"Regione\", \"Totale\"])]\n",
    "    dataset = dataset[dataset[\"Sesso\"] != \"T\"]\n",
    "    dataset = dataset[dataset[\"ETA\"] != 99]\n",
    "    \n",
    "    dataset = dataset.drop(columns=[\"Tipo aggregazione\", \"Codice aggregazione\"])\n",
    "    dataset[\"Aggregazione\"] = dataset[\"Aggregazione\"].str.capitalize()\n",
    "    datasets[i] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Aggregazione\": \"Area\",\n",
    "    \"Sesso\": \"Sesso\",\n",
    "    \"ETA\": \"Eta\",\n",
    "    \"Anno\": \"Anno\"\n",
    "}\n",
    "\n",
    "def categorize_age(age):\n",
    "    for i, age_range in enumerate(AGE_GROUP[\"categories\"]):\n",
    "        if age in age_range:\n",
    "            return AGE_GROUP[\"age_labels\"][i]\n",
    "    else:\n",
    "        return AGE_GROUP[\"age_labels\"][-1]\n",
    "    \n",
    "    \n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dataset = dataset.melt(id_vars=[ \"Aggregazione\", \"Sesso\", \"ETA\"],\n",
    "                        var_name=\"Anno\", value_name=\"Popolazione\")\n",
    "    \n",
    "    dataset['Anno'] = dataset['Anno'].str.extract('(\\d+)').astype(int)\n",
    "    \n",
    "    dataset['Fascia_Eta'] = pd.cut(dataset['ETA'], bins=AGE_GROUP[\"age_bins\"], labels=AGE_GROUP[\"age_labels\"], right=True, include_lowest=True)\n",
    "\n",
    "    dataset_pivot = dataset.pivot_table(index=['Aggregazione', 'Anno', 'Sesso'], \n",
    "                                        columns='Fascia_Eta', \n",
    "                                        values='Popolazione', \n",
    "                                        aggfunc='sum',\n",
    "                                        observed=True).reset_index()\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    datasets[i] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_1982-1991.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_1982-1991.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1992 agli anni 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_RAW_DATA + '1992-2001/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        year = filename.split('.')[0]\n",
    "        datasets[year] = pd.read_csv(SOURCE_PATH + filename, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df[df[\"Sesso\"] != \"Totale\"]\n",
    "    df = df.drop(columns=[\"Codice regione\"])\n",
    "    datasets[k] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"Area\",\n",
    "    \"Sesso\": \"Sesso\",\n",
    "    \"ETA\": \"Eta\",\n",
    "    \"Anno\": \"Anno\"\n",
    "}\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    df[\"Sesso\"] = df[\"Sesso\"].replace({\"Maschi\": \"M\", \"Femmine\": \"F\", \"Totale\": \"T\"})\n",
    "    df[\"ETA\"] = df[\"ETA\"].replace({\"100 e oltre\": 100}).astype(int)\n",
    "    df[\"Popolazione\"] = df[\"Popolazione\"].astype(int)\n",
    "    \n",
    "    \n",
    "    df['Fascia_Eta'] = pd.cut(df['ETA'], bins=AGE_GROUP[\"age_bins\"], labels=AGE_GROUP[\"age_labels\"], right=True, include_lowest=True)\n",
    "\n",
    "    dataset_pivot = df.pivot_table(index=['Regione', 'Anno', 'Sesso'], \n",
    "                                        columns='Fascia_Eta', \n",
    "                                        values='Popolazione', \n",
    "                                        aggfunc='sum',\n",
    "                                        observed=True).reset_index()\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    datasets[k] = dataset_pivot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visto che il dataset di questo periodo non presentano come Area l'Italia, dobbiamo applicare tecniche di feature engineering per crearla artifecialmente. \\\n",
    "Semplicemente sommiamo di uno specifico anno e sesso per ogni regione e creamo i dati relativi al paese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del terrorio nazionale\n",
    "\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df: pd.DataFrame\n",
    "    years = list(df[\"Anno\"].unique())\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = df[df[\"Anno\"] == year]\n",
    "        \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"Sesso\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"M\",\n",
    "            \"0-9\": df_year_m[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_m[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_m[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_m[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_m[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_m[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_m[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_m[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_m[\"80+\"].sum(),\n",
    "        }\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"Sesso\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"F\",\n",
    "            \"0-9\": df_year_f[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_f[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_f[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_f[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_f[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_f[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_f[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_f[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_f[\"80+\"].sum(),\n",
    "        }\n",
    "        new_item_f = pd.DataFrame([new_item_f])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_item_f], ignore_index=True)\n",
    "        datasets[k] = update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "final_dataset = final_dataset.sort_values(by=[\"Area\", \"Anno\", \"Sesso\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_1992-2001.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_1992-2001.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 2002 agli anni 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il file CSV di questo dataset Ã¨ formattato in modo non comune e ciÃ² complica la lettura da parte della libreria pandas. \\\n",
    "Per risolvere questo problema, creamo un codice che dal fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatazione dei file CSV\n",
    "SOURCE_PATH = PATH_RAW_DATA + '2002-2018/'\n",
    "\n",
    "DESTINATION_PATH = SOURCE_PATH + 'formatted/'\n",
    "\n",
    "BLACKLIST = [\n",
    "    \"\\\"Ricostruzione della popolazione intercensuaria - Popolazione al 1Â° gennaio per etÃ \\\"\\n\", \n",
    "    \"\\n\",\n",
    "    \"\\\"Popolazione per etÃ , vista per territorio - Tutte le regioni\\\"\\n\"\n",
    "]\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Divide una lista in sotto-liste di lunghezza n.\"\"\"\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "    \n",
    "    lines = []\n",
    "    with open(SOURCE_PATH + filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.replace('Territorio/EtÃ ;', 'Codice regione;Regione') for line in lines]\n",
    "        lines = [line.replace(';', ',') for line in lines]\n",
    "        lines = [line.replace(',,', ',') for line in lines]\n",
    "        lines = [line for line in lines if line not in BLACKLIST]\n",
    "    chunked_list = chunk_list(lines, 70)\n",
    "    \n",
    "    for chunck in chunked_list:\n",
    "        year = int(chunck[0].split(' ')[-1][:-2])\n",
    "        if \"Tutte le cittadinanze\" not in chunck[0]:\n",
    "            continue\n",
    "        \n",
    "        chunck = chunck[1:]\n",
    "        gender_chunk = chunk_list(chunck, 23)\n",
    "        \n",
    "        for inner_chunck in gender_chunk:\n",
    "            inner_chunck = inner_chunck[:-1]\n",
    "            gender = inner_chunck[1].split(',')[-1].strip()\n",
    "            del inner_chunck[1]\n",
    "            if gender not in [\"Maschi\", \"Femmine\"]:\n",
    "                continue\n",
    "            \n",
    "            with open(DESTINATION_PATH + f\"{year}_{gender[0]}.csv\", 'w') as f:\n",
    "                f.writelines(inner_chunck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = DESTINATION_PATH\n",
    "\n",
    "temp = {\n",
    "    str(year): {}\n",
    "    for year in range(2002, 2019 + 1)\n",
    "}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if not filename.endswith('.csv'):\n",
    "        continue\n",
    "    name = filename.split('.')[0]\n",
    "    year, gender = name.split('_')\n",
    "    \n",
    "    item = {\n",
    "        gender: pd.read_csv(SOURCE_PATH + filename, encoding='latin1')\n",
    "    }\n",
    "    temp[year].update(item)\n",
    "    \n",
    "    \n",
    "datasets = {}\n",
    "for year, data in temp.items():\n",
    "    for gender, df in data.items():\n",
    "        df[\"Sesso\"] = gender \n",
    "        data[gender] = df\n",
    "    datasets[year] = pd.concat(data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    if int(k) != 2019:    \n",
    "        df = df.drop(columns=[\"Codice regione\"])\n",
    "        datasets[k] = df\n",
    "        \n",
    "del datasets[\"2019\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"Area\",\n",
    "    \"Sesso\": \"Sesso\",\n",
    "    \"Anno\": \"Anno\"\n",
    "}\n",
    "\n",
    "def create_age_bins(df):\n",
    "        age_bins = {\n",
    "            '0-9': df[[str(i) for i in range(0, 10)]].sum(axis=1),\n",
    "            '10-19': df[[str(i) for i in range(10, 20)]].sum(axis=1),\n",
    "            '20-29': df[[str(i) for i in range(20, 30)]].sum(axis=1),\n",
    "            '30-39': df[[str(i) for i in range(30, 40)]].sum(axis=1),\n",
    "            '40-49': df[[str(i) for i in range(40, 50)]].sum(axis=1),\n",
    "            '50-59': df[[str(i) for i in range(50, 60)]].sum(axis=1),\n",
    "            '60-69': df[[str(i) for i in range(60, 70)]].sum(axis=1),\n",
    "            '70-79': df[[str(i) for i in range(70, 80)]].sum(axis=1),\n",
    "            '80+': df[[str(i) for i in range(80, 101)]].sum(axis=1)  # EtÃ  da 80 a 100 e oltre\n",
    "        }\n",
    "\n",
    "        # Creiamo un nuovo DataFrame solo con le colonne rilevanti\n",
    "        df_age_bins = pd.DataFrame(age_bins)\n",
    "        \n",
    "        return df_age_bins\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    \n",
    "    df_age_bins = create_age_bins(df)\n",
    "    df_final = pd.concat([df[['Anno', 'Regione', 'Sesso']], df_age_bins], axis=1)\n",
    "    df_final = df_final.rename(columns=COLUMN_NAMES)\n",
    "    datasets[k] = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del territorio nazionale\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df: pd.DataFrame\n",
    "    years = list(df[\"Anno\"].unique())\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = df[df[\"Anno\"] == year]\n",
    "        \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"Sesso\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"M\",\n",
    "            \"0-9\": df_year_m[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_m[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_m[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_m[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_m[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_m[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_m[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_m[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_m[\"80+\"].sum(),\n",
    "        }\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"Sesso\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"F\",\n",
    "            \"0-9\": df_year_f[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_f[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_f[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_f[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_f[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_f[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_f[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_f[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_f[\"80+\"].sum(),\n",
    "        }\n",
    "        new_item_f = pd.DataFrame([new_item_f])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_item_f], ignore_index=True)\n",
    "        datasets[k] = update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "final_dataset = final_dataset.sort_values(by=[\"Area\", \"Anno\", \"Sesso\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_2002-2018.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_2002-2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 2019 agli anni 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_RAW_DATA + '2019-2024/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv') and filename != '2024.csv':\n",
    "        year = filename.split('.')[0]\n",
    "        datasets[year] = pd.read_csv(SOURCE_PATH + filename, skiprows=1, encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "keep_columns = [\"Regione\", \"ETA\", \"Totale maschi\", \"Totale femmine\"]\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df[df[\"ETA\"] != 999]\n",
    "    df = df.drop(columns=[col for col in df.columns if col not in keep_columns])\n",
    "    datasets[k] = df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"Area\",\n",
    "}\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    \n",
    "    # Suddivisione tra maschi e femmine \n",
    "    df_male = df[[\"Anno\", \"Regione\", \"ETA\", \"Totale maschi\"]].copy()\n",
    "    df_male[\"Sesso\"] = \"M\"\n",
    "    df_male.rename(columns={\"Totale maschi\": \"Popolazione\"}, inplace=True)\n",
    "    \n",
    "    df_female = df[[\"Anno\", \"Regione\", \"ETA\", \"Totale femmine\"]].copy()\n",
    "    df_female[\"Sesso\"] = \"F\"\n",
    "    df_female.rename(columns={\"Totale femmine\": \"Popolazione\"}, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df_male, df_female], ignore_index=True)\n",
    "    \n",
    "    df['Fascia_Eta'] = pd.cut(df['ETA'], bins=AGE_GROUP[\"age_bins\"], labels=AGE_GROUP[\"age_labels\"], right=True, include_lowest=True)\n",
    "\n",
    "    dataset_pivot = df.pivot_table(index=['Regione', 'Anno', 'Sesso'], \n",
    "                                        columns='Fascia_Eta', \n",
    "                                        values='Popolazione', \n",
    "                                        aggfunc='sum',\n",
    "                                        observed=True).reset_index()\n",
    "    \n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    \n",
    "    datasets[k] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del terrorio nazionale\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    years = list(df[\"Anno\"].unique())\n",
    "    for year in years:\n",
    "        df_year = df[df[\"Anno\"] == year]\n",
    "    \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"Sesso\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"M\",\n",
    "            \"0-9\": df_year_m[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_m[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_m[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_m[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_m[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_m[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_m[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_m[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_m[\"80+\"].sum(),\n",
    "        }\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"Sesso\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"F\",\n",
    "            \"0-9\": df_year_f[\"0-9\"].sum(),\n",
    "            \"10-19\": df_year_f[\"10-19\"].sum(),\n",
    "            \"20-29\": df_year_f[\"20-29\"].sum(),\n",
    "            \"30-39\": df_year_f[\"30-39\"].sum(),\n",
    "            \"40-49\": df_year_f[\"40-49\"].sum(),\n",
    "            \"50-59\": df_year_f[\"50-59\"].sum(),\n",
    "            \"60-69\": df_year_f[\"60-69\"].sum(),\n",
    "            \"70-79\": df_year_f[\"70-79\"].sum(),\n",
    "            \"80+\": df_year_f[\"80+\"].sum(),\n",
    "        }\n",
    "        new_item_f = pd.DataFrame([new_item_f])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_item_f], ignore_index=True)\n",
    "        datasets[k] = update_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset = final_dataset.sort_values(by=[\"Area\", \"Anno\", \"Sesso\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione_2019-2023.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione_2019-2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "\n",
    "SOURCE_PATH = PATH_CLEANED_DATA\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.parquet'):\n",
    "        datasets.append(pd.read_parquet(SOURCE_PATH + filename))\n",
    "        \n",
    "dataset = pd.concat(datasets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [F] Popolazione totale\n",
    "\n",
    "age_columns = dataset.filter(regex=r'^\\d+-\\d+$').columns\n",
    "dataset['Popolazione_Totale'] = dataset[age_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [F] Percentuale di popolazione per fascia d'etÃ \n",
    "\n",
    "for col in age_columns:\n",
    "    dataset[col + '_Perc'] = (dataset[col] / dataset['Popolazione_Totale']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['Sex', 'Year', 'Territory'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5746/677241667.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Crescita_Popolazione_Totale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sesso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Crescita_Popolazione_Totale'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mage_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'Crescita_{col}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sesso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'Crescita_{col}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Territory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_project/Fut-Ita/venv/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6815\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6816\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6818\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6820\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_project/Fut-Ita/venv/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6946\u001b[0m         \u001b[0;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6947\u001b[0m         \u001b[0;31m# key that doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6953\u001b[0m             \u001b[0;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['Sex', 'Year', 'Territory'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# [F] Crescita della popolazione\n",
    "\n",
    "dataset = dataset.sort_values(by=['Area', 'Sesso', 'Anno'])\n",
    "\n",
    "dataset = dataset.fillna(0)\n",
    "dataset['Crescita_Popolazione_Totale'] = dataset.groupby(['Area', 'Sesso'])['Popolazione_Totale'].pct_change() * 100                                                   \n",
    "for col in age_columns:\n",
    "    dataset[f'Crescita_{col}'] = dataset.groupby(['Area', 'Sesso'])[col].pct_change() * 100\n",
    "                                        \n",
    "dataset['Crescita_Popolazione_Totale'] = dataset.groupby(['Area', 'Sesso'])['Crescita_Popolazione_Totale'].transform(lambda x: x.fillna(0))\n",
    "for col in age_columns:\n",
    "    dataset[f'Crescita_{col}'] = dataset.groupby(['Area', 'Sesso'])[f'Crescita_{col}'].transform(lambda x: x.fillna(0))\n",
    "    \n",
    "dataset = dataset.drop_duplicates(subset=['Anno', 'Area', 'Sesso'])\n",
    "\n",
    "print(dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
