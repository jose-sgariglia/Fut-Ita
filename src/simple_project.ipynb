{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie e costanti da usare\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.constant import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import joblib \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Settaggio\n",
    "def setup_logging(log_file):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    \n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def close_logger(logger):\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Datasets ISTAT\n",
    "Ri-formatto i dataset ISTAT con procedura di cleaning. Una volta creati i vari dataset, verranno mergiati in un unico dataset a cui si proceder√† al feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1952 agli anni 1971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura del dataset\n",
    "\n",
    "SOURCE_PATH = RAW_DATA_DEMOGRAPHICS + '1952-1971/'\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        datasets.append(pd.read_csv(SOURCE_PATH + filename, encoding='latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dataset\n",
    "\n",
    "def convert_eta(eta):\n",
    "    if eta.startswith('Y_GE'):\n",
    "        return 100 \n",
    "    else:\n",
    "        return int(eta[1:])\n",
    "    \n",
    "def convert_sesso(sesso):\n",
    "    if sesso == 1:\n",
    "        return 'M'\n",
    "    elif sesso == 2:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'T'\n",
    "\n",
    "colums_to_keep = ['Territorio', 'ETA1', 'TIME', 'SEXISTAT1', 'Value']\n",
    "\n",
    "for i, df in enumerate(datasets):\n",
    "    df = df[colums_to_keep]\n",
    "\n",
    "    df = df[df['ETA1'] != 'TOTAL']\n",
    "    df['ETA1']= df[\"ETA1\"].apply(convert_eta)\n",
    "\n",
    "    df['SEXISTAT1'] = df['SEXISTAT1'].apply(convert_sesso)\n",
    "\n",
    "    df = df[df['Territorio'].isin(list(MAPPING_REGION.keys()))]\n",
    "    datasets[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione del dataset\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    'Territorio': 'Area',\n",
    "    'ETA1': 'Eta',\n",
    "    'TIME': 'Anno',\n",
    "    'SEXISTAT1': 'Sesso',\n",
    "}\n",
    "\n",
    "def categorize_age(age):\n",
    "    for i, age_range in enumerate(AGE_GROUP[\"categories\"]):\n",
    "        if age in age_range:\n",
    "            return AGE_GROUP[\"age_labels\"][i]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "for i, df in enumerate(datasets):\n",
    "    df = df.rename(columns=COLUMN_NAMES)\n",
    "\n",
    "    df['fascia_eta'] = df['Eta'].apply(categorize_age)\n",
    "    \n",
    "    df = df.groupby(['Area', 'Sesso', 'Anno', 'fascia_eta'], as_index=False)['Value'].sum()\n",
    "\n",
    "    dataset_pivot = df.pivot_table(\n",
    "        index=['Area', 'Sesso', 'Anno'], \n",
    "        columns='fascia_eta', \n",
    "        values='Value', \n",
    "        aggfunc='sum', \n",
    "        observed=True\n",
    "        ).reset_index()\n",
    "\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot['Area'] = dataset_pivot['Area'].replace(MAPPING_REGION)\n",
    "    datasets[i] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dataset\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '1952-1971/'\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset = final_dataset.drop_duplicates()\n",
    "\n",
    "final_dataset.sort_values(by=['Area', 'Sesso', 'Anno'], inplace=True)\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1972 agli anni 1981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura del dataset\n",
    "\n",
    "SOURCE_PATH = RAW_DATA_DEMOGRAPHICS + '1972-1981/'\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        datasets.append(pd.read_csv(SOURCE_PATH + filename, encoding='latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dataset\n",
    "\n",
    "def convert_eta(eta):\n",
    "    if eta.startswith('Y_GE'):\n",
    "        return 100 \n",
    "    else:\n",
    "        return int(eta[1:])\n",
    "    \n",
    "def convert_sesso(sesso):\n",
    "    if sesso == 1:\n",
    "        return 'M'\n",
    "    elif sesso == 2:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'T'\n",
    "\n",
    "colums_to_keep = ['Territorio', 'ETA1', 'TIME', 'SEXISTAT1', 'Value']\n",
    "\n",
    "for i, df in enumerate(datasets):\n",
    "    df = df[colums_to_keep]\n",
    "\n",
    "    df = df[df['ETA1'] != 'TOTAL']\n",
    "    df['ETA1']= df[\"ETA1\"].apply(convert_eta)\n",
    "\n",
    "    df['SEXISTAT1'] = df['SEXISTAT1'].apply(convert_sesso)\n",
    "\n",
    "    df = df[df['Territorio'].isin(list(MAPPING_REGION.keys()))]\n",
    "    datasets[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione del dataset\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    'Territorio': 'Area',\n",
    "    'ETA1': 'Eta',\n",
    "    'TIME': 'Anno',\n",
    "    'SEXISTAT1': 'Sesso',\n",
    "}\n",
    "\n",
    "def categorize_age(age):\n",
    "    for i, age_range in enumerate(AGE_GROUP[\"categories\"]):\n",
    "        if age in age_range:\n",
    "            return AGE_GROUP[\"age_labels\"][i]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "for i, df in enumerate(datasets):\n",
    "    df = df.rename(columns=COLUMN_NAMES)\n",
    "\n",
    "    df['fascia_eta'] = df['Eta'].apply(categorize_age)\n",
    "    \n",
    "    df = df.groupby(['Area', 'Sesso', 'Anno', 'fascia_eta'], as_index=False)['Value'].sum()\n",
    "\n",
    "    dataset_pivot = df.pivot_table(\n",
    "        index=['Area', 'Sesso', 'Anno'], \n",
    "        columns='fascia_eta', \n",
    "        values='Value', \n",
    "        aggfunc='sum', \n",
    "        observed=True\n",
    "        ).reset_index()\n",
    "\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot['Area'] = dataset_pivot['Area'].replace(MAPPING_REGION)\n",
    "    datasets[i] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dataset\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '1972-1981/'\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset = final_dataset.drop_duplicates()\n",
    "\n",
    "final_dataset.sort_values(by=['Area', 'Sesso', 'Anno'], inplace=True)\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1982 agli anni 1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = RAW_DATA_DEMOGRAPHICS + '1982-1991/'\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        datasets.append(pd.read_csv(SOURCE_PATH + filename, sep=';', encoding='latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dataset = dataset[dataset[\"Tipo aggregazione\"].isin([\"Regione\", \"Totale\"])]\n",
    "    dataset = dataset[dataset[\"ETA\"] != 99]\n",
    "    \n",
    "    dataset = dataset.drop(columns=[\"Tipo aggregazione\", \"Codice aggregazione\"])\n",
    "    dataset[\"Aggregazione\"] = dataset[\"Aggregazione\"].str.capitalize()\n",
    "    datasets[i] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Aggregazione\": \"Area\",\n",
    "    \"Sesso\": \"Sesso\",\n",
    "    \"ETA\": \"Eta\",\n",
    "    \"Anno\": \"Anno\"\n",
    "}\n",
    "\n",
    "def categorize_age(age):\n",
    "    for i, age_range in enumerate(AGE_GROUP[\"categories\"]):\n",
    "        if age in age_range:\n",
    "            return AGE_GROUP[\"age_labels\"][i]\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    dataset = dataset.melt(id_vars=[ \"Aggregazione\", \"Sesso\", \"ETA\"],\n",
    "                        var_name=\"Anno\", value_name=\"Popolazione\")\n",
    "    \n",
    "    dataset['Anno'] = dataset['Anno'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "    dataset['fascia_eta'] = dataset['ETA'].apply(get_age_group)\n",
    "    dateset = dataset.groupby(['Aggregazione', 'Sesso', 'Anno', 'fascia_eta'], as_index=False)['Popolazione'].sum()\n",
    "\n",
    "    dataset_pivot = dateset.pivot_table(\n",
    "        index=['Aggregazione', 'Sesso', 'Anno'], \n",
    "        columns='fascia_eta', \n",
    "        values='Popolazione', \n",
    "        aggfunc='sum', \n",
    "        observed=True\n",
    "        ).reset_index()\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    dataset_pivot['Area'] = dataset_pivot['Area'].replace(MAPPING_REGION)\n",
    "    datasets[i] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '1982-1991/'\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset = final_dataset.drop_duplicates()\n",
    "\n",
    "final_dataset.sort_values(by=['Area', 'Anno', 'Sesso'], inplace=True)\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 1992 agli anni 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = RAW_DATA_DEMOGRAPHICS + '1992-2001/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        year = filename.split('.')[0]\n",
    "        datasets[year] = pd.read_csv(SOURCE_PATH + filename, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df.drop(columns=[\"Codice regione\"])\n",
    "    datasets[k] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"Area\",\n",
    "    \"Sesso\": \"Sesso\",\n",
    "    \"ETA\": \"Eta\",\n",
    "    \"Anno\": \"Anno\"\n",
    "}\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    df[\"Sesso\"] = df[\"Sesso\"].replace({\"Maschi\": \"M\", \"Femmine\": \"F\", \"Totale\": \"T\"})\n",
    "    df[\"ETA\"] = df[\"ETA\"].replace({\"100 e oltre\": 100}).astype(int)\n",
    "    df[\"Popolazione\"] = df[\"Popolazione\"].astype(int)\n",
    "\n",
    "    df['fascia_eta'] = df['ETA'].apply(get_age_group)\n",
    "    dataset_pivot = df.pivot_table(\n",
    "            index=['Regione', 'Sesso', 'Anno'], \n",
    "            columns='fascia_eta', \n",
    "            values='Popolazione', \n",
    "            aggfunc='sum', \n",
    "            observed=True\n",
    "            ).reset_index()\n",
    "\n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    dataset_pivot['Area'] = dataset_pivot['Area'].replace(MAPPING_REGION)\n",
    "    datasets[k] = dataset_pivot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visto che il dataset di questo periodo non presentano come Area l'Italia, dobbiamo applicare tecniche di feature engineering per crearla artifecialmente. \\\n",
    "Semplicemente sommiamo di uno specifico anno e sesso per ogni regione e creamo i dati relativi al paese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del terrorio nazionale\n",
    "\n",
    "\n",
    "for k in list(datasets.keys()):\n",
    "    df = datasets[k]\n",
    "    years = list(df[\"Anno\"].unique())\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = df[df[\"Anno\"] == year]\n",
    "        \n",
    "        # Creazione del territorio nazionale Maschile\n",
    "        df_year_m = df_year[df_year[\"Sesso\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"M\"\n",
    "        }\n",
    "        \n",
    "        # Aggiungiamo dinamicamente le fasce di et√†\n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_m[label] = df_year_m[label].sum()\n",
    "\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "\n",
    "        \n",
    "        # Creazione del territorio nazionale Femminile\n",
    "        df_year_f = df_year[df_year[\"Sesso\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"F\"\n",
    "        }\n",
    "        \n",
    "        # Aggiungiamo dinamicamente le fasce di et√†\n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_f[label] = df_year_f[label].sum()\n",
    "\n",
    "        new_df_f = pd.DataFrame([new_item_f])\n",
    "\n",
    "\n",
    "        # Creazione del territorio nazionale Totale\n",
    "        df_year_t = df_year[df_year[\"Sesso\"] == \"T\"]\n",
    "        new_item_t = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"T\"\n",
    "        }\n",
    "\n",
    "        # Aggiungiamo dinamicamente le fasce di et√†\n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_t[label] = df_year_t[label].sum()\n",
    "\n",
    "        new_df_t = pd.DataFrame([new_item_t])\n",
    "        \n",
    "        # Concatenare i nuovi dati al DataFrame esistente\n",
    "        update_df = pd.concat([df, new_df_m, new_df_f, new_df_t], ignore_index=True)\n",
    "        datasets[year] = update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '1992-2001/'\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset = final_dataset.drop_duplicates()\n",
    "\n",
    "final_dataset = final_dataset.sort_values(by=[\"Area\", \"Anno\", \"Sesso\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 2002 agli anni 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il file CSV di questo dataset √® formattato in modo non comune e ci√≤ complica la lettura da parte della libreria pandas. \\\n",
    "Per risolvere questo problema, creamo un codice che dal fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatazione dei file CSV\n",
    "SOURCE_PATH = RAW_DATA_DEMOGRAPHICS + '2002-2018/'\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '2002-2018/formatted/'\n",
    "\n",
    "BLACKLIST = [\n",
    "    \"\\\"Ricostruzione della popolazione intercensuaria - Popolazione al 1¬∞ gennaio per et√†\\\"\\n\", \n",
    "    \"\\n\",\n",
    "    \"\\\"Popolazione per et√†, vista per territorio - Tutte le regioni\\\"\\n\"\n",
    "]\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Divide una lista in sotto-liste di lunghezza n.\"\"\"\n",
    "    return [lst[i:i + n] for i in range(0, len(lst), n)]\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "    \n",
    "    lines = []\n",
    "    with open(SOURCE_PATH + filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.replace('Territorio/Et√†;', 'Codice regione;Regione') for line in lines]\n",
    "        lines = [line.replace(';', ',') for line in lines]\n",
    "        lines = [line.replace(',,', ',') for line in lines]\n",
    "        lines = [line for line in lines if line not in BLACKLIST]\n",
    "    chunked_list = chunk_list(lines, 70)\n",
    "    \n",
    "    for chunck in chunked_list:\n",
    "        year = int(chunck[0].split(' ')[-1][:-2])\n",
    "        if \"Tutte le cittadinanze\" not in chunck[0]:\n",
    "            continue\n",
    "        \n",
    "        chunck = chunck[1:]\n",
    "        gender_chunk = chunk_list(chunck, 23)\n",
    "        \n",
    "        for inner_chunck in gender_chunk:\n",
    "            inner_chunck = inner_chunck[:-1]\n",
    "            gender = inner_chunck[1].split(',')[-1].strip()\n",
    "            del inner_chunck[1]\n",
    "            \n",
    "            with open(DESTINATION_PATH + f\"{year}_{gender[0]}.csv\", 'w') as f:\n",
    "                f.writelines(inner_chunck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = DESTINATION_PATH\n",
    "\n",
    "temp = {\n",
    "    str(year): {}\n",
    "    for year in range(2002, 2018 + 1)\n",
    "}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if not filename.endswith('.csv') or filename.startswith('2019'):\n",
    "        continue\n",
    "    name = filename.split('.')[0]\n",
    "    year, gender = name.split('_')\n",
    "    \n",
    "    item = {\n",
    "        gender: pd.read_csv(SOURCE_PATH + filename, encoding='latin1')\n",
    "    }\n",
    "    temp[year].update(item)\n",
    "    \n",
    "    \n",
    "datasets = {}\n",
    "for year, data in temp.items():\n",
    "    for gender, df in data.items():\n",
    "        df[\"Sesso\"] = gender \n",
    "        data[gender] = df\n",
    "    datasets[year] = pd.concat(data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df.drop(columns=[\"Codice regione\"])\n",
    "    datasets[k] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"Area\",\n",
    "    \"Sesso\": \"Sesso\",\n",
    "    \"Anno\": \"Anno\"\n",
    "}\n",
    "\n",
    "def create_age_bins(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    age_bins = {}\n",
    "    \n",
    "    for age_range, label in zip(AGE_GROUP['categories'], AGE_GROUP['age_labels']):\n",
    "        if label == AGE_GROUP['age_labels'][-1]:\n",
    "            columns = [str(i) for i in range(85, 100)]  # Colonne corrispondenti alla fascia di et√†\n",
    "        else:\n",
    "            columns = [str(i) for i in age_range]\n",
    "        age_bins[label] = df[columns].sum(axis=1)  # Somma lungo la riga per ciascun gruppo\n",
    "    \n",
    "    df_age_bins = pd.DataFrame(age_bins)\n",
    "    \n",
    "    return df_age_bins\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    \n",
    "    df_age_bins = create_age_bins(df)\n",
    "    df_final = pd.concat([df[['Anno', 'Regione', 'Sesso']], df_age_bins], axis=1)\n",
    "    df_final = df_final.rename(columns=COLUMN_NAMES)\n",
    "    df_final['Area'] = df_final['Area'].replace(MAPPING_REGION)\n",
    "    datasets[k] = df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del territorio nazionale\n",
    "\n",
    "for k in list(datasets.keys()):\n",
    "    df = datasets[k]\n",
    "    df: pd.DataFrame\n",
    "    years = list(df[\"Anno\"].unique())\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = df[df[\"Anno\"] == year]\n",
    "        \n",
    "        df_year_m = df_year[df_year[\"Sesso\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"M\"\n",
    "        }\n",
    "        \n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_m[label] = df_year_m[label].sum()\n",
    "\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "\n",
    "        \n",
    "        df_year_f = df_year[df_year[\"Sesso\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"F\"\n",
    "        }\n",
    "        \n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_f[label] = df_year_f[label].sum()\n",
    "\n",
    "        new_df_f = pd.DataFrame([new_item_f])\n",
    "\n",
    "\n",
    "        df_year_t = df_year[df_year[\"Sesso\"] == \"T\"]\n",
    "        new_item_t = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"T\"\n",
    "        }\n",
    "\n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_t[label] = df_year_t[label].sum()\n",
    "\n",
    "        new_df_t = pd.DataFrame([new_item_t])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_df_f, new_df_t], ignore_index=True)\n",
    "        datasets[year] = update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '2002-2018/'\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset.drop_duplicates(inplace=True)\n",
    "final_dataset = final_dataset.sort_values(by=[\"Area\", \"Anno\", \"Sesso\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dagli anni 2019 agli anni 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dei dati\n",
    "\n",
    "SOURCE_PATH = RAW_DATA_DEMOGRAPHICS + '2019-2024/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(SOURCE_PATH):\n",
    "    if filename.endswith('.csv') and filename != '2024.csv':\n",
    "        year = filename.split('.')[0]\n",
    "        datasets[year] = pd.read_csv(SOURCE_PATH + filename, skiprows=1, encoding='latin1', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dei dati\n",
    "\n",
    "keep_columns = [\"Regione\", \"ETA\", \"Totale maschi\", \"Totale femmine\", \"Totale\"]\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df = df[df[\"ETA\"] != 999]\n",
    "    df = df.drop(columns=[col for col in df.columns if col not in keep_columns])\n",
    "    datasets[k] = df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strutturazione dei dati\n",
    "\n",
    "COLUMN_NAMES = {\n",
    "    \"Regione\": \"Area\",\n",
    "}\n",
    "\n",
    "for k, df in datasets.items():\n",
    "    df[\"Anno\"] = int(k)\n",
    "    \n",
    "    # Suddivisione tra maschi e femmine \n",
    "    df_male = df[[\"Anno\", \"Regione\", \"ETA\", \"Totale maschi\"]].copy()\n",
    "    df_male[\"Sesso\"] = \"M\"\n",
    "    df_male.rename(columns={\"Totale maschi\": \"Popolazione\"}, inplace=True)\n",
    "    \n",
    "    df_female = df[[\"Anno\", \"Regione\", \"ETA\", \"Totale femmine\"]].copy()\n",
    "    df_female[\"Sesso\"] = \"F\"\n",
    "    df_female.rename(columns={\"Totale femmine\": \"Popolazione\"}, inplace=True)\n",
    "\n",
    "    df_total = df[[\"Anno\", \"Regione\", \"ETA\", \"Totale\"]].copy()\n",
    "    df_total[\"Sesso\"] = \"T\"\n",
    "    df_total.rename(columns={\"Totale\": \"Popolazione\"}, inplace=True)\n",
    "    \n",
    "    df = pd.concat([df_male, df_female, df_total], ignore_index=True)\n",
    "    df['fascia_eta'] = df['ETA'].apply(get_age_group)\n",
    "\n",
    "    df = df.groupby(['Regione', 'Sesso', 'Anno', 'fascia_eta'], as_index=False)['Popolazione'].sum()\n",
    "    dataset_pivot = df.pivot_table(\n",
    "            index=['Regione', 'Sesso', 'Anno'], \n",
    "            columns='fascia_eta', \n",
    "            values='Popolazione', \n",
    "            aggfunc='sum', \n",
    "            observed=True\n",
    "            ).reset_index()\n",
    "    \n",
    "    dataset_pivot.columns.name = None \n",
    "    dataset_pivot = dataset_pivot.rename_axis(None, axis=1) \n",
    "    dataset_pivot = dataset_pivot.rename(columns=COLUMN_NAMES)\n",
    "    dataset_pivot['Area'] = dataset_pivot['Area'].replace(MAPPING_REGION)\n",
    "    datasets[k] = dataset_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunta del terrorio nazionale\n",
    "\n",
    "for k in list(datasets.keys()):\n",
    "\n",
    "    df = datasets[k]\n",
    "    years = list(df[\"Anno\"].unique())\n",
    "    for year in years:\n",
    "        df_year = df[df[\"Anno\"] == year]\n",
    "        \n",
    "        df_year_m = df_year[df_year[\"Sesso\"] == \"M\"]\n",
    "        new_item_m = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"M\"\n",
    "        }\n",
    "        \n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_m[label] = df_year_m[label].sum()\n",
    "\n",
    "        new_df_m = pd.DataFrame([new_item_m])\n",
    "\n",
    "        \n",
    "        df_year_f = df_year[df_year[\"Sesso\"] == \"F\"]\n",
    "        new_item_f = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"F\"\n",
    "        }\n",
    "        \n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_f[label] = df_year_f[label].sum()\n",
    "\n",
    "        new_df_f = pd.DataFrame([new_item_f])\n",
    "\n",
    "\n",
    "        df_year_t = df_year[df_year[\"Sesso\"] == \"T\"]\n",
    "        new_item_t = {\n",
    "            \"Area\": \"Italia\",\n",
    "            \"Anno\": year,\n",
    "            \"Sesso\": \"T\"\n",
    "        }\n",
    "\n",
    "        for label in AGE_GROUP[\"age_labels\"]:\n",
    "            new_item_t[label] = df_year_t[label].sum()\n",
    "\n",
    "        new_df_t = pd.DataFrame([new_item_t])\n",
    "        \n",
    "        update_df = pd.concat([df, new_df_m, new_df_f, new_df_t], ignore_index=True)\n",
    "        datasets[year] = update_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = PROCESSED_DATA_DEMOGRAPHICS + '2019-2023/'\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "    \n",
    "final_dataset = pd.concat(datasets, ignore_index=True)\n",
    "final_dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "final_dataset = final_dataset.sort_values(by=[\"Area\", \"Anno\", \"Sesso\"])\n",
    "final_dataset.to_parquet(DESTINATION_PATH + 'popolazione.parquet', index=False)\n",
    "final_dataset.to_csv(DESTINATION_PATH + 'popolazione.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "\n",
    "SOURCE_PATH = PROCESSED_DATA_DEMOGRAPHICS\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for dirname in os.listdir(SOURCE_PATH):\n",
    "    for filename in os.listdir(SOURCE_PATH + dirname + \"/\"):\n",
    "        if filename.endswith('.parquet'):\n",
    "            datasets.append(pd.read_parquet(SOURCE_PATH + dirname + '/' + filename))\n",
    "        \n",
    "dataset = pd.concat(datasets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [F] Popolazione totale\n",
    "\n",
    "age_columns = AGE_GROUP[\"age_labels\"]\n",
    "dataset['Popolazione_Totale'] = dataset[age_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [F] Percentuale di popolazione per fascia d'et√†\n",
    "\n",
    "for col in age_columns:\n",
    "    dataset[col + '_Perc'] = (dataset[col] / dataset['Popolazione_Totale']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [F] Crescita della popolazione\n",
    "\n",
    "dataset = dataset.sort_values(by=['Area', 'Sesso', 'Anno'])\n",
    "\n",
    "dataset = dataset.fillna(0)\n",
    "dataset['Crescita_Popolazione_Totale'] = dataset.groupby(['Area', 'Sesso'])['Popolazione_Totale'].pct_change() * 100                                                   \n",
    "for col in age_columns:\n",
    "    dataset[f'Crescita_{col}'] = dataset.groupby(['Area', 'Sesso'])[col].pct_change() * 100\n",
    "                                        \n",
    "dataset['Crescita_Popolazione_Totale'] = dataset.groupby(['Area', 'Sesso'])['Crescita_Popolazione_Totale'].transform(lambda x: x.fillna(0))\n",
    "for col in age_columns:\n",
    "    dataset[f'Crescita_{col}'] = dataset.groupby(['Area', 'Sesso'])[f'Crescita_{col}'].transform(lambda x: x.fillna(0))\n",
    "    \n",
    "dataset = dataset.drop_duplicates(subset=['Anno', 'Area', 'Sesso'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio dei dati\n",
    "\n",
    "DESTINATION_PATH = CLEANED_DATA_DEMOGRAPHICS\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "dataset.to_parquet(os.path.join(DESTINATION_PATH, 'popolazione.parquet'), index=False)\n",
    "dataset.to_csv(os.path.join(DESTINATION_PATH, 'popolazione.csv'), index=False)\n",
    "\n",
    "DESTINATION_PATH = CLEANED_DATA_DEMOGRAPHICS + 'by_area/'\n",
    "\n",
    "for area in dataset['Area'].unique():\n",
    "    \n",
    "    dataset_area = dataset[dataset['Area'] == area]\n",
    "    code_area = ITALIAN_REGION_CODE[area]\n",
    "    path = os.path.join(DESTINATION_PATH, code_area)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    dataset_area = dataset_area.sort_values(by=['Anno', 'Sesso'])\n",
    "    dataset_area.to_parquet(os.path.join(path, 'popolazione.parquet'), index=False)\n",
    "    dataset_area.to_csv(os.path.join(path, 'popolazione.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei dati\n",
    "\n",
    "age_description_dict = {label: f\"Fascia di et√† dai {label.split('-')[0]} anni ai {label.split('-')[1]} anni\" if '-' in label else f\"Fascia di et√† dagli {label.split('+')[0]} anni in su\" for label in AGE_GROUP[\"age_labels\"]}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for code in ITALIAN_REGION_CODE.values():\n",
    "    path = CLEANED_DATA_DEMOGRAPHICS + f'by_area/{code}/'\n",
    "    datasets[code] = pd.read_parquet(path + 'popolazione.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C1] Grafico della popolazione per fascia di et√† e sesso\n",
    "\n",
    "DESTINATION_PATH = DEMO_YEAR_CHART_PATH\n",
    "\n",
    "def plot_population_by_age_and_sex(data, year_to_analyze, territory_to_analyze, output_dir):\n",
    "    data_filtered = data[(data['Anno'] == year_to_analyze) & (data['Area'] == territory_to_analyze)]\n",
    "\n",
    "    male_data, female_data = (data_filtered[data_filtered['Sesso'] == i] for i in [\"M\", \"F\"])\n",
    "    age_keys = list(age_description_dict.keys())\n",
    "    if not all(key in data_filtered.columns for key in age_keys):\n",
    "        raise ValueError(\"Le colonne delle fasce di et√† non sono presenti nel dataframe.\")\n",
    "\n",
    "    male_population = male_data[age_keys].sum().values\n",
    "    female_population = female_data[age_keys].sum().values\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    bar_width = 0.4\n",
    "    indices = np.arange(len(age_description_dict))\n",
    "\n",
    "    plt.barh(indices - bar_width/2, male_population, bar_width, color='blue', label='Maschi')\n",
    "    plt.barh(indices + bar_width/2, female_population, bar_width, color='violet', label='Femmine')\n",
    "\n",
    "    plt.yticks(indices, age_description_dict.values())\n",
    "    plt.xlabel('Popolazione')\n",
    "    plt.ylabel('Fascia di Et√†')\n",
    "    plt.title(f'Popolazione per Fascia di Et√† e Sesso in {territory_to_analyze} nel {year_to_analyze}')\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(axis='x', linestyle='--')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'population_{year_to_analyze}.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DESTINATION_PATH + code + '/'\n",
    "    for year in data['Anno'].unique():\n",
    "        area = ITALIAN_REGIONE_BY_CODE[code]\n",
    "        plot_population_by_age_and_sex(data, year, area, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C2] Grafico cartesiano della popolazione - gender specific\n",
    "\n",
    "DESTINATION_PATH = DEMO_TOTAL_CHART_PATH \n",
    "\n",
    "def plot_age_group_growth(data, age_start, age_end, territory, output_dir):\n",
    "    format_col_age = f\"{age_start}-{age_end}\"\n",
    "\n",
    "    if format_col_age == \"85-89\":\n",
    "        format_col_age = \"85+\"\n",
    "\n",
    "    if format_col_age not in data.columns:\n",
    "        raise Exception()\n",
    "\n",
    "    data = data[data['Area'] == territory]\n",
    "    male_population, female_population = [], []\n",
    "    years = data['Anno'].unique()\n",
    "\n",
    "    for year in years:\n",
    "        male_population.append(int(data[(data[\"Sesso\"] == \"M\") & (data[\"Anno\"] == year)][format_col_age].values[0]))\n",
    "        female_population.append(int(data[(data[\"Sesso\"] == \"F\") & (data[\"Anno\"] == year)][format_col_age].values[0]))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(years, male_population, label='Maschi', color='blue', marker='o')\n",
    "    plt.plot(years, female_population, label='Femmine', color='violet', marker='o')\n",
    "\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "    plt.title(f'Popolazione per la Fascia di Et√† {age_start}-{age_end} in {territory}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    max_population = max(max(male_population), max(female_population))\n",
    "    step_size = max_population // 12\n",
    "    plt.yticks(np.arange(0, max_population + step_size, step_size))\n",
    "    plt.ylim(bottom=0)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'{age_start}_{age_end}.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DESTINATION_PATH + f\"{code}/gender-specific/ages/\"\n",
    "    ante = 0\n",
    "    for post in range(4, 90, 5):\n",
    "        area = ITALIAN_REGIONE_BY_CODE[code]\n",
    "        plot_age_group_growth(data, ante, post, ITALIAN_REGIONE_BY_CODE[code], path)\n",
    "        ante += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C2] Grigli di grafici cartesiani della popolazione - gender specific\n",
    "\n",
    "DESTINATION_PATH = DEMO_TOTAL_CHART_PATH\n",
    "\n",
    "def plot_age_group_growth_grid(dataset, territory, output_dir):\n",
    "    dataset = dataset[dataset['Area'] == territory]\n",
    "    fig, axs = plt.subplots(3, 6, figsize=(18, 18)) \n",
    "    axs = axs.ravel()\n",
    "\n",
    "    max_population = dataset[AGE_GROUP[\"age_labels\"]].max().max()\n",
    "    step_size = max_population // 12\n",
    "\n",
    "    years = dataset['Anno'].unique()\n",
    "    for i, col_name in enumerate(AGE_GROUP[\"age_labels\"]):\n",
    "        male_population, female_population = [], []\n",
    "        \n",
    "        for year in years:\n",
    "            male_population.append(int(dataset[(dataset[\"Sesso\"] == \"M\") & (dataset[\"Anno\"] == year)][col_name].values[0]))\n",
    "            female_population.append(int(dataset[(dataset[\"Sesso\"] == \"F\") & (dataset[\"Anno\"] == year)][col_name].values[0]))\n",
    "\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.plot(years, male_population, label='Maschi', color='blue')\n",
    "        ax.plot(years, female_population, label='Femmine', color='violet')\n",
    "        ax.set_title(col_name, fontsize=10)\n",
    "        ax.set_xlabel('Anno')\n",
    "        ax.set_ylabel('Popolazione')\n",
    "        ax.grid(True)\n",
    "        ax.set_yticks(np.arange(0, max_population + step_size * 2, step_size))\n",
    "        \n",
    "    for ax in axs[len(AGE_GROUP[\"age_labels\"]):]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "\n",
    "    fig.legend(['Maschi', 'Femmine'], loc='upper right', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'grid_ages.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DESTINATION_PATH + code + '/gender-specific/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    plot_age_group_growth_grid(data, ITALIAN_REGIONE_BY_CODE[code], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C2] Grafico cartesiano della popolazione totale\n",
    "\n",
    "def plot_tot_polutation(data, territory, output_path):\n",
    "    data = data[data['Area'] == territory]\n",
    "    data = data[data['Sesso'] == 'T']\n",
    "\n",
    "    years = data[\"Anno\"].unique()\n",
    "    tp = []\n",
    "    for year in years:\n",
    "        data_year = data[data[\"Anno\"] == year]\n",
    "        tp.append(data_year[\"Popolazione_Totale\"].sum())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(years, tp, marker='o', color='blue')\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "\n",
    "    plt.xticks(years, rotation=90)\n",
    "    max_population = max(tp)\n",
    "    step_size = max_population // 12\n",
    "    min_population = min(tp) - step_size if min(tp) - step_size > 0 else 0\n",
    "    plt.yticks(np.arange(min_population, max_population + (2*step_size), step_size))\n",
    "    plt.title(f'Popolazione Totale in {territory} negli anni')\n",
    "    plt.grid(True)\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_path, 'popolazione_totale.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DEMO_TOTAL_CHART_PATH + code + '/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    plot_tot_polutation(data, ITALIAN_REGIONE_BY_CODE[code], path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C2] Griglia di grafici cartesiani della popolazione totale\n",
    "\n",
    "def plot_total_age_group_growth_grid(dataset, territory, output_dir):\n",
    "    dataset = dataset[dataset['Area'] == territory]\n",
    "    fig, axs = plt.subplots(3, 6, figsize=(18, 18)) \n",
    "    axs = axs.ravel()\n",
    "\n",
    "    max_population = dataset[AGE_GROUP[\"age_labels\"]].max().max()\n",
    "    step_size = max_population // 12\n",
    "\n",
    "    years = dataset['Anno'].unique()\n",
    "    for i, col_name in enumerate(AGE_GROUP[\"age_labels\"]):\n",
    "        total_population = []\n",
    "        \n",
    "        for year in years:\n",
    "            total_population.append(int(dataset[(dataset[\"Sesso\"] == \"T\") & (dataset[\"Anno\"] == year)][col_name].values[0]))\n",
    "\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.plot(years, total_population, label='Totale', color='red')\n",
    "        ax.set_title(col_name, fontsize=10)\n",
    "        ax.set_xlabel('Anno')\n",
    "        ax.set_ylabel('Popolazione')\n",
    "        ax.grid(True)\n",
    "        ax.set_yticks(np.arange(0, max_population + step_size * 2, step_size))\n",
    "        \n",
    "    for ax in axs[len(AGE_GROUP[\"age_labels\"]):]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'griglia_popolazione_totale.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DEMO_TOTAL_CHART_PATH + code + '/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    plot_total_age_group_growth_grid(data, ITALIAN_REGIONE_BY_CODE[code], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C3] Grafico cartesiano della crescita della popolazione - gender specific\n",
    "\n",
    "DESTINATION_PATH = DEMO_GROWTH_CHART_PATH\n",
    "\n",
    "def plot_age_group_growth(data, age_start, age_end, territory, output_dir):\n",
    "    format_col_age = f\"Crescita_{age_start}-{age_end}\"\n",
    "\n",
    "    if format_col_age == \"Crescita_85-89\":\n",
    "        format_col_age = \"Crescita_85+\"\n",
    "\n",
    "    if format_col_age not in data.columns:\n",
    "        raise Exception(f\"Colonna {format_col_age} non presente nel dataset.\")\n",
    "\n",
    "    data = data[data['Area'] == territory]\n",
    "    male_population, female_population = [], []\n",
    "    years = data['Anno'].unique()\n",
    "\n",
    "    for year in years:\n",
    "        male_population.append(data[(data[\"Sesso\"] == \"M\") & (data[\"Anno\"] == year)][format_col_age].values[0])\n",
    "        female_population.append(data[(data[\"Sesso\"] == \"F\") & (data[\"Anno\"] == year)][format_col_age].values[0])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(years, male_population, label='Maschi', color='blue', marker='o', alpha=0.7)   \n",
    "    plt.plot(years, female_population, label='Femmine', color='violet', marker='o', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "    plt.title(f'Crescita della Popolazione per la Fascia di Et√† {age_start}-{age_end} in {territory}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'{age_start}_{age_end}.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "if not os.path.exists(DESTINATION_PATH):\n",
    "    os.makedirs(DESTINATION_PATH)\n",
    "\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DESTINATION_PATH + f\"{code}/gender_specific/ages/\"\n",
    "    ante = 0\n",
    "    for post in range(4, 90, 5):\n",
    "        area = ITALIAN_REGIONE_BY_CODE[code]\n",
    "        plot_age_group_growth(data, ante, post, ITALIAN_REGIONE_BY_CODE[code], path)\n",
    "        ante += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C3] Griglia di grafici cartesiani della crescita della popolazione - gender specific\n",
    "\n",
    "DESTINATION_PATH = DEMO_GROWTH_CHART_PATH\n",
    "\n",
    "def plot_age_group_growth_grid(dataset, territory, output_dir):\n",
    "    dataset = dataset[dataset['Area'] == territory]\n",
    "    fig, axs = plt.subplots(3, 6, figsize=(20, 12)) \n",
    "    axs = axs.ravel()\n",
    "\n",
    "    max_population = 10\n",
    "    step_size = 1\n",
    "\n",
    "    years = dataset['Anno'].unique()\n",
    "    for i, col_name in enumerate(AGE_GROUP[\"age_labels\"]):\n",
    "        male_population, female_population = [], []\n",
    "        col_name = f'Crescita_{col_name}'\n",
    "        \n",
    "        for year in years:\n",
    "            male_population.append(dataset[(dataset[\"Sesso\"] == \"M\") & (dataset[\"Anno\"] == year)][col_name].values[0])\n",
    "            female_population.append(dataset[(dataset[\"Sesso\"] == \"F\") & (dataset[\"Anno\"] == year)][col_name].values[0])\n",
    "\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.plot(years, male_population, label='Maschi', color='blue')\n",
    "        ax.plot(years, female_population, label='Femmine', color='violet')\n",
    "        ax.set_title(col_name, fontsize=10)\n",
    "        ax.set_xlabel('Anno')\n",
    "        ax.set_ylabel('Popolazione')\n",
    "        ax.grid(True)\n",
    "        ax.set_yticks(np.arange(- max_population, max_population + step_size * 2, step_size))\n",
    "        \n",
    "    for ax in axs[len(AGE_GROUP[\"age_labels\"]):]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "\n",
    "    fig.legend(['Maschi', 'Femmine'], loc='upper right', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'grid_ages.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DESTINATION_PATH + code + '/gender_specific/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    plot_age_group_growth_grid(data, ITALIAN_REGIONE_BY_CODE[code], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C3] Grafico cartesiano della crescita della popolazione totale\n",
    "\n",
    "def plot_tot_polutation(data, territory, output_path):\n",
    "    data = data[data['Area'] == territory]\n",
    "    data = data[data['Sesso'] == 'T']\n",
    "\n",
    "    years = data[\"Anno\"].unique()\n",
    "    tp = []\n",
    "    for year in years:\n",
    "        data_year = data[data[\"Anno\"] == year]\n",
    "        tp.append(data_year[\"Crescita_Popolazione_Totale\"].sum())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(years, tp, marker='o', color='blue')\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "\n",
    "    plt.xticks(years, rotation=45)\n",
    "    plt.title(f'Popolazione Totale in {territory} negli anni')\n",
    "    plt.grid(True)\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_path, 'crescita_popolazione_totale.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DEMO_GROWTH_CHART_PATH + code + '/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    plot_tot_polutation(data, ITALIAN_REGIONE_BY_CODE[code], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C3] Griglia di grafici della crescita della popolazione totale\n",
    "\n",
    "def plot_total_age_group_growth_grid(dataset, territory, output_dir):\n",
    "    dataset = dataset[dataset['Area'] == territory]\n",
    "    fig, axs = plt.subplots(3, 6, figsize=(20, 12)) \n",
    "    axs = axs.ravel()\n",
    "\n",
    "    max_population = 10\n",
    "    step_size = 1\n",
    "\n",
    "    years = dataset['Anno'].unique()\n",
    "    for i, col_name in enumerate(AGE_GROUP[\"age_labels\"]):\n",
    "        total_population = []\n",
    "        format_col_name = f'Crescita_{col_name}'\n",
    "        \n",
    "        for year in years:\n",
    "            total_population.append(dataset[(dataset[\"Sesso\"] == \"T\") & (dataset[\"Anno\"] == year)][format_col_name].values[0])\n",
    "\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.plot(years, total_population, label='Totale', color='red')\n",
    "        ax.set_title(col_name, fontsize=10)\n",
    "        ax.set_xlabel('Anno')\n",
    "        ax.set_ylabel('Popolazione')\n",
    "        ax.grid(True)\n",
    "        ax.set_yticks(np.arange(-max_population, max_population, step_size))\n",
    "        \n",
    "    for ax in axs[len(AGE_GROUP[\"age_labels\"]):]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'griglia_crescita_popolazione_totale.jpeg'))\n",
    "    plt.close()\n",
    "\n",
    "# For every region\n",
    "for code, data in tqdm(datasets.items()):\n",
    "    path = DEMO_GROWTH_CHART_PATH + code + '/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    plot_total_age_group_growth_grid(data, ITALIAN_REGIONE_BY_CODE[code], path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento Dataset\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# for code in ITALIAN_REGION_CODE.values():\n",
    "for code in ['ITA']:\n",
    "    path = CLEANED_DATA_DEMOGRAPHICS + f'by_area/{code}/'\n",
    "    item = {}\n",
    "    item[\"path\"] = path\n",
    "    dataset = pd.read_parquet(path + 'popolazione.parquet')\n",
    "\n",
    "    item[\"male_data\"] = dataset[dataset[\"Sesso\"] == \"M\"]\n",
    "    item[\"female_data\"] = dataset[dataset[\"Sesso\"] == \"F\"]\n",
    "    item[\"total_data\"] = dataset[dataset[\"Sesso\"] == \"T\"]\n",
    "\n",
    "    cutoff = 0.8\n",
    "    item[\"cutoff\"] = cutoff\n",
    "\n",
    "    lenght_cutoff = int(len(dataset[\"Anno\"].unique()) * cutoff)\n",
    "    item[\"train_data\"] = dataset[:lenght_cutoff]\n",
    "    item[\"test_data\"] = dataset[lenght_cutoff:]\n",
    "\n",
    "    datasets[code] = item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Regressione Lineare\n",
    "\n",
    "for code, item in datasets.items():\n",
    "    for label in AGE_GROUP[\"age_labels\"] + ['all']:\n",
    "        model_dir = os.path.join(DEMO_LR_MODEL_PATH.format(code), f'{label}/')\n",
    "        log_dir = os.path.join(DEMO_LR_MODEL_PATH.format(code), f'{label}/logs/')\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "        # Imposta il logging\n",
    "        log_file = os.path.join(log_dir,  f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "        logger = setup_logging(log_file)\n",
    "        \n",
    "        # Aggiungi timestamp e informazioni sul dataset\n",
    "        logger.info(f\"========== Report per {code} [Age: {label}] - Demografico ==========\")\n",
    "        logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "        logger.info(f\"Dataset Path: {item['path']}\")\n",
    "        logger.info(f\"Model: Linear Regression\\n\")\n",
    "\n",
    "        logger.info(f\"Train Cut Off: {item['cutoff']:.2f}\")\n",
    "        logger.info(f\"Test Cut Off: {1 - item['cutoff']:.2f}\\n\")\n",
    "\n",
    "        try:\n",
    "            for dataset_type, data in item.items():\n",
    "                if dataset_type not in ['male_data', 'female_data', 'total_data']:\n",
    "                    continue\n",
    "                logger.info(f\"-------- Dataset Type: {dataset_type} --------\")\n",
    "\n",
    "                lenght_cutoff = int(len(data[\"Anno\"].unique()) * item[\"cutoff\"])\n",
    "                train_data = data[:lenght_cutoff]\n",
    "                test_data = data[lenght_cutoff:]\n",
    "\n",
    "                # Prepara i dati\n",
    "                x_train = train_data[\"Anno\"].values.reshape(-1, 1)\n",
    "                y_train = train_data[\"Popolazione_Totale\"].values if label == 'all' else train_data[label].values\n",
    "\n",
    "                x_test = test_data[\"Anno\"].values.reshape(-1, 1)\n",
    "                y_test = test_data[\"Popolazione_Totale\"].values if label == 'all' else test_data[label].values\n",
    "\n",
    "                # Addestra il modello\n",
    "                model = LinearRegression()\n",
    "                model.fit(x_train, y_train)\n",
    "\n",
    "                # Effettua le previsioni\n",
    "                y_pred = model.predict(x_test)\n",
    "\n",
    "                # Calcola le metriche di performance\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                # Log delle metriche\n",
    "                logger.info(f\"Metrics:\")\n",
    "                logger.info(f\"\\tMAE: {mae:.4f}\")\n",
    "                logger.info(f\"\\tMSE: {mse:.4f}\")\n",
    "                logger.info(f\"\\tRMSE: {rmse:.4f}\")\n",
    "                logger.info(f\"\\tR2 Score: {r2:.4f}\\n\")\n",
    "\n",
    "                # Salvataggio del modello\n",
    "                filename = model_dir + f'model_{dataset_type}.pkl'\n",
    "                joblib.dump(model, filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore durante l'addestramento del modello per il dataset {code}: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            logger.info(f\"=====================================\\n\")\n",
    "            close_logger(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Regressione Polinomiale\n",
    "\n",
    "for code, item in datasets.items():\n",
    "    for label in AGE_GROUP[\"age_labels\"] + ['all']:\n",
    "        model_dir = os.path.join(DEMO_PR_MODEL_PATH.format(code), f'{label}/')\n",
    "        log_dir = os.path.join(DEMO_PR_MODEL_PATH.format(code), f'{label}/logs/')\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "        # Imposta il logging\n",
    "        log_file = os.path.join(log_dir, f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "        logger = setup_logging(log_file)\n",
    "\n",
    "        # Aggiungi timestamp e informazioni sul dataset\n",
    "        logger.info(f\"========== Report per {code} - Demografico ==========\")\n",
    "        logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "        logger.info(f\"Dataset Path: {item['path']}\")\n",
    "        logger.info(f\"Model: Polynomial Regression\\n\")\n",
    "\n",
    "        logger.info(f\"Train Cut Off: {item['cutoff']:.2f}\")\n",
    "        logger.info(f\"Test Cut Off: {1 - item['cutoff']:.2f}\\n\")\n",
    "\n",
    "        try:\n",
    "            for dataset_type, data in item.items():\n",
    "                if dataset_type not in ['male_data', 'female_data', 'total_data']:\n",
    "                    continue\n",
    "                logger.info(f\"-------- Dataset Type: {dataset_type} --------\")\n",
    "\n",
    "                lenght_cutoff = int(len(data[\"Anno\"].unique()) * item[\"cutoff\"])\n",
    "                train_data = data[:lenght_cutoff]\n",
    "                test_data = data[lenght_cutoff:]\n",
    "\n",
    "                # Prepara i dati\n",
    "                x_train = train_data[\"Anno\"].values.reshape(-1, 1)\n",
    "                y_train = train_data[\"Popolazione_Totale\"].values if label == 'all' else train_data[label].values\n",
    "\n",
    "                x_test = test_data[\"Anno\"].values.reshape(-1, 1)\n",
    "                y_test = test_data[\"Popolazione_Totale\"].values if label == 'all' else test_data[label].values\n",
    "\n",
    "                # Addestra il modello\n",
    "                degree = 10\n",
    "\n",
    "                logging.info(\"Model Info:\")\n",
    "                logging.info(f\"\\tDegree of Polynomial: {degree}\\n\")\n",
    "\n",
    "                poly = PolynomialFeatures(degree=degree)\n",
    "                x_train_poly = poly.fit_transform(x_train)\n",
    "                x_test_poly = poly.transform(x_test)\n",
    "\n",
    "                poly_model = LinearRegression() \n",
    "                poly_model.fit(x_train_poly, y_train)\n",
    "\n",
    "                y_pred_poly = poly_model.predict(x_test_poly)   \n",
    "\n",
    "                # Calcola le metriche di performance\n",
    "                mae = mean_absolute_error(y_test, y_pred_poly)\n",
    "                mse = mean_squared_error(y_test, y_pred_poly)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "                # Log delle metriche\n",
    "                logger.info(f\"Metrics:\")\n",
    "                logger.info(f\"\\tMAE: {mae:.4f}\")\n",
    "                logger.info(f\"\\tMSE: {mse:.4f}\")\n",
    "                logger.info(f\"\\tRMSE: {rmse:.4f}\")\n",
    "                logger.info(f\"\\tR2 Score: {r2:.4f}\\n\")\n",
    "\n",
    "                # Salvataggio del modello\n",
    "                filename = model_dir + f'model_{dataset_type}.pkl'\n",
    "                model_to_save = {\n",
    "                    \"model\": poly_model,\n",
    "                    \"poly_features\": poly\n",
    "                }\n",
    "                joblib.dump(model_to_save, filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Errore durante l'addestramento del modello per il dataset {code}: {str(e)}\")\n",
    "\n",
    "        finally:\n",
    "            logger.info(f\"=====================================\\n\")\n",
    "            close_logger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [M] Random Forest Regressor\n",
    "\n",
    "for code, item in datasets.items():\n",
    "    model_dir = os.path.join(DEMO_RF_MODEL_PATH.format(code), 'all/')\n",
    "    log_dir = os.path.join(DEMO_RF_MODEL_PATH.format(code), f'all/logs/')\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Imposta il logging\n",
    "    log_file = os.path.join(log_dir, f'log_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.txt')\n",
    "    logger = setup_logging(log_file)\n",
    "\n",
    "    # Aggiungi timestamp e informazioni sul dataset\n",
    "    logger.info(f\"========== Report per {code} - Demografico ==========\")\n",
    "    logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\")\n",
    "    logger.info(f\"Dataset Path: {item['path']}\")\n",
    "    logger.info(f\"Model: RandomForest Regressor\\n\")\n",
    "\n",
    "    logger.info(f\"Train Cut Off: {item['cutoff']:.2f}\")\n",
    "    logger.info(f\"Test Cut Off: {1 - item['cutoff']:.2f}\\n\")\n",
    "\n",
    "    try:\n",
    "        for dataset_type, data in item.items():\n",
    "            if dataset_type not in ['male_data', 'female_data', 'total_data']:\n",
    "                continue\n",
    "            logger.info(f\"-------- Dataset Type: {dataset_type} --------\")\n",
    "\n",
    "            lenght_cutoff = int(len(data[\"Anno\"].unique()) * item[\"cutoff\"])\n",
    "            train_data = data[:lenght_cutoff]\n",
    "            test_data = data[lenght_cutoff:]\n",
    "\n",
    "            # Prepara i dati\n",
    "            x_train = train_data[\"Anno\"].values.reshape(-1, 1)\n",
    "            y_train = train_data[\"Popolazione_Totale\"].values\n",
    "\n",
    "            x_test = test_data[\"Anno\"].values.reshape(-1, 1)\n",
    "            y_test = test_data[\"Popolazione_Totale\"].values\n",
    "\n",
    "            # Addestra il modello Random Forest\n",
    "            n_estimators = 1000\n",
    "            max_depth = 5\n",
    "            random_state = 42\n",
    "            max_features = 'log2'\n",
    "\n",
    "            logger.info(\"Model Info:\")\n",
    "            logger.info(f\"\\tNumber of Estimators: {n_estimators}\")\n",
    "            logger.info(f\"\\tMax Depth: {max_depth}\")\n",
    "            logger.info(f\"\\tMax Features: {max_features}\\n\")\n",
    "\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                random_state=random_state,\n",
    "                max_features=max_features\n",
    "            )\n",
    "\n",
    "            rf_model.fit(x_train, y_train)\n",
    "            y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "            # Calcola le metriche di performance\n",
    "            mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "            mse = mean_squared_error(y_test, y_pred_rf)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "            # Log delle metriche\n",
    "            logger.info(f\"Metrics:\")\n",
    "            logger.info(f\"\\tMAE: {mae:.4f}\")\n",
    "            logger.info(f\"\\tMSE: {mse:.4f}\")\n",
    "            logger.info(f\"\\tRMSE: {rmse:.4f}\")\n",
    "            logger.info(f\"\\tR2 Score: {r2:.4f}\\n\")\n",
    "\n",
    "            # Salvataggio del modello\n",
    "            filename = model_dir + f'model_{dataset_type}.pkl'\n",
    "            joblib.dump(rf_model, filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Errore durante l'addestramento del modello per il dataset {code}: {str(e)}\")\n",
    "\n",
    "    finally:\n",
    "        logger.info(f\"=====================================\\n\")\n",
    "        close_logger(logger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing\n",
    "Confrontare i dati reali con i dati previsti dal modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento Dataset e Modelli\n",
    "\n",
    "datasets = {}\n",
    "models = {}\n",
    "model_dir = DEMO_MODEL_PATH\n",
    "\n",
    "# for code in ITALIAN_REGION_CODE.values():\n",
    "for code in ['ITA']:\n",
    "    path = CLEANED_DATA_DEMOGRAPHICS + f'by_area/{code}/'\n",
    "    \n",
    "    # Caricamento del dataset\n",
    "    item = {}\n",
    "    dataset = pd.read_parquet(path + 'popolazione.parquet')\n",
    "\n",
    "    item[\"male\"] = dataset[dataset[\"Sesso\"] == \"M\"]\n",
    "    item[\"female\"] = dataset[dataset[\"Sesso\"] == \"F\"]\n",
    "    item[\"total\"] = dataset[dataset[\"Sesso\"] == \"T\"]\n",
    "    \n",
    "    datasets[code] = item \n",
    "    \n",
    "    item = {}\n",
    "    \n",
    "    item[\"LinearRegression\"] = {}\n",
    "    for ages in ['all'] + AGE_GROUP[\"age_labels\"]:\n",
    "        nested_item = {}\n",
    "        \n",
    "        nested_item[\"male\"] = joblib.load(DEMO_LR_MODEL_PATH.format(code) + f'{ages}/model_male_data.pkl')\n",
    "        nested_item[\"female\"] = joblib.load(DEMO_LR_MODEL_PATH.format(code) + f'{ages}/model_female_data.pkl')\n",
    "        nested_item[\"total\"] = joblib.load(DEMO_LR_MODEL_PATH.format(code) + f'{ages}/model_total_data.pkl')\n",
    "        \n",
    "        item[\"LinearRegression\"][ages] = nested_item\n",
    "    \n",
    "    # item[\"PolynomialRegression\"] = {}\n",
    "    # for ages in ['all'] + AGE_GROUP[\"age_labels\"]:\n",
    "    #     nested_item = {}\n",
    "        \n",
    "    #     nested_item[\"male\"] = joblib.load(DEMO_PR_MODEL_PATH.format(code) + f'{ages}/model_male_data.pkl')\n",
    "    #     nested_item[\"female\"] = joblib.load(DEMO_PR_MODEL_PATH.format(code) + f'{ages}/model_female_data.pkl')\n",
    "    #     nested_item[\"total\"] = joblib.load(DEMO_PR_MODEL_PATH.format(code) + f'{ages}/model_total_data.pkl')\n",
    "        \n",
    "    #     item[\"PolynomialRegression\"][ages] = nested_item\n",
    "    \n",
    "    # item[\"RandomForestRegressor\"] = {}\n",
    "    # for ages in ['all'] + AGE_GROUP[\"age_labels\"]:\n",
    "    #     nested_item = {}\n",
    "        \n",
    "    #     nested_item[\"male\"] = joblib.load(DEMO_RF_MODEL_PATH.format(code) + f'{ages}/model_male_data.pkl')\n",
    "    #     nested_item[\"female\"] = joblib.load(DEMO_RF_MODEL_PATH.format(code) + f'{ages}/model_female_data.pkl')\n",
    "    #     nested_item[\"total\"] = joblib.load(DEMO_RF_MODEL_PATH.format(code) + f'{ages}/model_total_data.pkl')\n",
    "        \n",
    "    #     item[\"RandomForestRegressor\"][ages] = nested_item\n",
    "    \n",
    "    models[code] = item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C1] Confonto Realt√† vs Predizione - Regressione Lineare\n",
    "\n",
    "def compare_real_vs_lr(data, model, output_dir, predict_column='Popolazione_Totale', info=None):\n",
    "    x = data[\"Anno\"].values.reshape(-1, 1)\n",
    "    y = data[predict_column].values\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data[\"Anno\"], y, label='Reale', color='blue')\n",
    "    plt.plot(data[\"Anno\"], y_pred, label='Predetto', color='red')\n",
    "\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "    if info is None:\n",
    "        plt.title('Confronto Realt√† vs Predizione - Regressione Lineare')\n",
    "    else:\n",
    "        plt.title(f'Confronto Realt√† vs Predizione [Code: {info[0]}, Sesso: {info[2]}, Age: {info[1]}] - Regressione Lineare')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, 'real_vs_pred.jpeg'))\n",
    "    plt.close()\n",
    "    \n",
    "# For every region\n",
    "for code, dataset in datasets.items():\n",
    "    age_models = models[code][\"LinearRegression\"]\n",
    "    \n",
    "    for age, model in age_models.items():\n",
    "        chart_dir = DEMO_MODEL_CHART_PATH.format(code=code)\n",
    "\n",
    "        if not os.path.exists(chart_dir):\n",
    "            os.makedirs(chart_dir)\n",
    "            \n",
    "        for dataset_type, data in dataset.items():\n",
    "            dest_path = chart_dir + f'linear_regression/by_age/{age}/{dataset_type}/'\n",
    "            info = [code, age, dataset_type]\n",
    "            if age in ['all']:\n",
    "                compare_real_vs_lr(data=data, model=model[dataset_type], output_dir=dest_path, info=info)\n",
    "            else:\n",
    "                compare_real_vs_lr(data, model[dataset_type], dest_path, predict_column=age, info=info)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] Confronto Realt√† vs Predizione - Regressione Polinomiale\n",
    "\n",
    "def compare_real_vs_pl(data, model, poly, output_dir):\n",
    "    x = data[\"Anno\"].values.reshape(-1, 1)\n",
    "    y = data[\"Popolazione_Totale\"].values\n",
    "    \n",
    "    x_poly = poly.transform(x)\n",
    "    y_pred = model.predict(x_poly)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data[\"Anno\"], y, label='Reale', color='blue')\n",
    "    plt.plot(data[\"Anno\"], y_pred, label='Predetto', color='red')\n",
    "\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "    plt.title('Confronto Realt√† vs Predizione - Regressione Polinomiale')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, 'real_vs_pred.jpeg'))\n",
    "    plt.close()\n",
    "    \n",
    "# For every region\n",
    "for code, dataset in datasets.items():\n",
    "    model = models[code][\"PolynomialRegression\"]\n",
    "    path = DEMO_MODEL_CHART_PATH + code + '/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    for dataset_type, data in dataset.items():\n",
    "        if dataset_type not in ['path']:\n",
    "            model_data = model[dataset_type][\"model\"]\n",
    "            poly_data = model[dataset_type][\"poly_features\"]\n",
    "            compare_real_vs_pl(data, model_data, poly_data, path + f'polynomial_regression/{dataset_type}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [C] Confronto Realt√† vs Predizione - Random Forest Regressor\n",
    "\n",
    "def compare_real_vs_rf(data, model, output_dir):\n",
    "    x = data[\"Anno\"].values.reshape(-1, 1)\n",
    "    y = data[\"Popolazione_Totale\"].values\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data[\"Anno\"], y, label='Reale', color='blue')\n",
    "    plt.plot(data[\"Anno\"], y_pred, label='Predetto', color='red')\n",
    "\n",
    "    plt.xlabel('Anno')\n",
    "    plt.ylabel('Popolazione')\n",
    "    plt.title('Confronto Realt√† vs Predizione - Random Forest Regressor')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, 'real_vs_pred.jpeg'))\n",
    "    plt.close()\n",
    "    \n",
    "# For every region\n",
    "for code, dataset in datasets.items():\n",
    "    model = models[code][\"RandomForestRegressor\"]\n",
    "    path = DEMO_MODEL_CHART_PATH + code + '/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    for dataset_type, data in dataset.items():\n",
    "        if dataset_type not in ['path']:\n",
    "            compare_real_vs_rf(data, model[dataset_type], path + f'random_forest/{dataset_type}/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
